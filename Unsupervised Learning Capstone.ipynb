{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the corpus\n",
    "from nltk.corpus import brown, stopwords\n",
    "\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate the DataFrame with the fileids\n",
    "df['ID'] = brown.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ca01\n",
       "1    ca02\n",
       "2    ca03\n",
       "3    ca04\n",
       "4    ca05\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate the DataFrame with the text\n",
    "\n",
    "text = [] # Create an empty list where the text can be stored\n",
    "for each in df['ID']:\n",
    "    txt = brown.words(fileids = [each]) # This returns the text based on the fileid \n",
    "    txt = [i.lower() for i in txt]\n",
    "    txt = ' '.join(txt)\n",
    "    text.append(txt) # Add the text to the list   \n",
    "\n",
    "df['text'] = text # Create a new column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text\n",
       "0  ca01  the fulton county grand jury said friday an in...\n",
       "1  ca02  austin , texas -- committee approval of gov. p...\n",
       "2  ca03  several defendants in the summerdale police bu...\n",
       "3  ca04  oslo the most positive element to emerge from ...\n",
       "4  ca05  east providence should organize its civil defe..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text genre\n",
       "0  ca01  the fulton county grand jury said friday an in...  news\n",
       "1  ca02  austin , texas -- committee approval of gov. p...  news\n",
       "2  ca03  several defendants in the summerdale police bu...  news\n",
       "3  ca04  oslo the most positive element to emerge from ...  news\n",
       "4  ca05  east providence should organize its civil defe...  news"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the DataFrame with the genre of the text\n",
    "\n",
    "categories = []\n",
    "for each in df['ID']:\n",
    "    cat = brown.categories(fileids = [each])\n",
    "    cat = ' '.join(cat)\n",
    "    categories.append(cat)\n",
    "\n",
    "df['genre'] = categories\n",
    "\n",
    "df.head() # Take a look at the DataFrame to see what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'),\n",
    "                            max_df=0.5,\n",
    "                            min_df=0.1,\n",
    "                            lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df.genre\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(true_k)\n",
    "lsa = make_pipeline(svd,Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=15, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9,  3, 14, 10,  7, 14, 14,  3,  8, 12, 12, 12, 12, 12,  4,  4,\n",
       "        4,  3,  6,  4,  4,  4, 10,  3,  3,  3,  3,  4,  4,  8, 12,  4, 10,\n",
       "        9,  7, 14, 12, 12, 12, 14, 14,  3,  3,  7, 14, 10, 14, 10, 14, 14,\n",
       "        8, 10,  1, 14, 10,  1, 10,  3,  9, 14, 14, 14, 14, 14, 14, 14,  1,\n",
       "       14, 14, 14,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1, 10,  1,  1, 10,\n",
       "        6, 14,  3, 11,  8,  8,  8,  8,  8,  8, 11,  8, 11, 11, 11,  2,  8,\n",
       "       11,  8,  8, 10,  2, 14,  1,  4,  3,  2,  5, 12, 12,  6,  6, 13,  2,\n",
       "        2,  2,  2,  6,  2,  2,  2,  1,  1,  9,  5,  9,  3,  3,  9,  3,  3,\n",
       "        3,  3,  5,  3,  3,  1,  6, 11,  9,  2,  1, 11,  1,  6,  4,  2,  1,\n",
       "        3, 14, 11,  6,  6,  6, 11,  6,  2,  6, 14,  6,  9,  2,  2,  6,  4,\n",
       "        9,  4,  9,  9,  3,  2, 13,  8, 12, 11,  3,  8,  6,  1, 11,  6,  7,\n",
       "        9, 11,  6, 14, 14, 13,  2,  1, 14,  6, 11,  7, 11,  1, 11, 13,  1,\n",
       "       11,  6,  1, 11,  5, 14, 11, 11, 11, 11,  1,  6,  6, 11,  5,  1,  4,\n",
       "        1,  1, 14, 10,  6, 14,  1, 10,  4, 11, 11, 11, 10, 11,  0,  6,  1,\n",
       "        6,  1, 14,  6,  0,  8, 11,  9,  6,  6,  0, 11, 14, 11, 10, 11,  6,\n",
       "        4,  9, 11, 11, 11, 14,  1,  1,  6,  3,  3, 14,  7,  7,  7,  7,  7,\n",
       "        7,  3,  5,  7, 10,  7,  2,  7,  7, 14, 14,  3,  3,  7,  3,  7, 14,\n",
       "       10,  3,  9,  3, 14,  5,  5,  5,  5,  5,  5,  5,  5,  5,  1,  2,  5,\n",
       "        2,  5,  5,  5,  5,  5,  5,  5,  5, 14, 11, 11, 11,  5,  9, 11,  9,\n",
       "        1,  1,  5,  1,  5,  5, 14, 14,  9,  1,  3,  3, 14,  7,  7,  5,  7,\n",
       "        9,  9,  9,  3, 11, 11, 11, 11, 13,  6, 11,  6,  5,  3,  2, 11, 11,\n",
       "        1,  1,  1, 11,  1,  5,  5,  5,  5,  5,  3,  5,  5,  2,  5,  7,  5,\n",
       "        0, 13,  0,  8,  0,  8,  0,  1, 13,  8, 13,  0,  0,  0,  0, 13,  0,\n",
       "        0,  0,  0, 13,  4, 13,  0,  0,  0, 13,  0,  0,  0,  0, 13, 13, 13,\n",
       "       13,  0, 10,  0,  0,  0,  0,  0,  0,  4, 13,  0,  0, 13,  4, 13,  0,\n",
       "        0,  0,  0,  6, 11,  0,  1,  0,  0, 13, 13, 13, 13,  0, 13, 13,  0,\n",
       "        0, 13, 13, 13, 13, 13, 13,  0,  0,  0, 13,  0, 13,  0,  0, 13, 13,\n",
       "        0,  0, 13, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,\n",
       "        0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0, 13,  0,  0, 10,  0,  0,\n",
       "        1, 10,  0,  1,  0,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39266299793743681"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819388602370859"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38722669280174105"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16796493654276209"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>adventure</th>\n",
       "      <th>belles_lettres</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>humor</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>mystery</th>\n",
       "      <th>news</th>\n",
       "      <th>religion</th>\n",
       "      <th>reviews</th>\n",
       "      <th>romance</th>\n",
       "      <th>science_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  adventure  belles_lettres  editorial  fiction  government  hobbies  \\\n",
       "k                                                                           \n",
       "0             12               3          0       17           0        0   \n",
       "1              0              13          3        1           0        3   \n",
       "2              0               1          0        0           1        9   \n",
       "3              0               0          1        0           8        9   \n",
       "4              0               3          0        1           0        1   \n",
       "5              0               2          0        0           1        3   \n",
       "6              0              13          0        0           0        3   \n",
       "7              0               1          1        0          12        0   \n",
       "8              0               1          1        3           0        0   \n",
       "9              0               2          1        0           1        3   \n",
       "10             0               4          5        0           2        1   \n",
       "11             0              21          0        0           0        0   \n",
       "12             0               0          0        0           0        2   \n",
       "13            17               2          0        7           0        1   \n",
       "14             0               9         15        0           5        1   \n",
       "\n",
       "genre  humor  learned  lore  mystery  news  religion  reviews  romance  \\\n",
       "k                                                                        \n",
       "0          4        0     0       14     0         0        0       24   \n",
       "1          4        9     5        0     0         0       11        0   \n",
       "2          0        4     6        0     0         1        0        0   \n",
       "3          0        5     3        0     9         0        1        0   \n",
       "4          0        0     3        2     9         0        0        1   \n",
       "5          0       33     0        0     0         0        0        0   \n",
       "6          0        2    11        0     1         0        1        0   \n",
       "7          0        4     1        0     3         0        0        0   \n",
       "8          0        0     2        0     2        10        0        1   \n",
       "9          0        6     6        0     2         0        0        0   \n",
       "10         1        0     0        1     3         0        3        1   \n",
       "11         0       12     7        0     0         6        0        0   \n",
       "12         0        0     1        0     9         0        0        0   \n",
       "13         0        1     1        7     0         0        0        2   \n",
       "14         0        4     2        0     6         0        1        0   \n",
       "\n",
       "genre  science_fiction  \n",
       "k                       \n",
       "0                    3  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    1  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   1  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['k'] = km.labels_\n",
    "\n",
    "pd.crosstab(df['k'], df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: got eyes went thought knew door looked room going told something house face think felt asked woman mother let us\n",
      "\n",
      "Cluster 1: music art love miss us young performance mother century form book though york experience stage american mr sense english often\n",
      "\n",
      "Cluster 2: water surface used feet system small state head shown air area body earth light side pressure ground half size 10\n",
      "\n",
      "Cluster 3: per 000 year industry cost program development system company million 1960 car market service equipment business cent government rate production\n",
      "\n",
      "Cluster 4: mrs mr house president miss car white room home year family club woman police door wife school office children mother\n",
      "\n",
      "Cluster 5: surface used system pressure shown number volume type water systems per information material method study range low small obtained possible\n",
      "\n",
      "Cluster 6: south war north southern john river american company england wrote west english east states 000 century city year united york\n",
      "\n",
      "Cluster 7: state states federal court united law year government secretary department 000 congress public county act shall per program labor general\n",
      "\n",
      "Cluster 8: church god john religious members us faith st city say england sunday love law peace spirit board death heart social\n",
      "\n",
      "Cluster 9: school college students schools children education university student class social child year training members program board family girls president study\n",
      "\n",
      "Cluster 10: mr american president state party miss music city program york brown committee john got war board us car night house\n",
      "\n",
      "Cluster 11: social human experience us society sense religious century political art fact form community history self moral values literature power action\n",
      "\n",
      "Cluster 12: game year season home hit club play run john shot field york four bill week 30 record state got president\n",
      "\n",
      "Cluster 13: eyes door water head got looked feet went car face saw side knew house away hand turned across road street\n",
      "\n",
      "Cluster 14: president united war states government american state nations political military mr national policy economic secretary party administration west peace 000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try the clusters using the DataFrame that does not inclue science fiction, humor, reviews or religion--\n",
    "# df1\n",
    "\n",
    "labels1 = df1.genre\n",
    "true_k1 = np.unique(labels1).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize the text in the new DataFrame--use the vectorizer that we use in Unsupervised learning\n",
    "\n",
    "X1 = vectorizer.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the kmeans cluster\n",
    "fit_km = km.fit(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign the labels to a column in the new DataFrame\n",
    "\n",
    "labels_km = km.labels_\n",
    "df1['k'] = labels_km\n",
    "centers1 = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30832209604947969"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(labels1, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28786868024763501"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(labels1, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29774454221584984"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(labels1, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10508326804476567"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(labels1, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>adventure</th>\n",
       "      <th>belles_lettres</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>mystery</th>\n",
       "      <th>news</th>\n",
       "      <th>romance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  adventure  belles_lettres  editorial  fiction  government  hobbies  \\\n",
       "k                                                                           \n",
       "0              0               0          0        0           2        2   \n",
       "1              0               2          1        0           0        3   \n",
       "2              0               1          1        0          13       10   \n",
       "3              0               5          0        0           0        1   \n",
       "4              0               0          0        0           1        3   \n",
       "5              0              13          1        1           1        2   \n",
       "6              0              14          1        0           0        0   \n",
       "7              0              11         20        0           5        2   \n",
       "8              0              12          1        1           1        2   \n",
       "9              1               2          0        2           0        1   \n",
       "10            10               5          0       10           0        1   \n",
       "11            18               5          0       14           0        2   \n",
       "12             0               2          1        1           0        0   \n",
       "13             0               0          1        0           6        4   \n",
       "14             0               3          0        0           1        3   \n",
       "\n",
       "genre  learned  lore  mystery  news  romance  \n",
       "k                                             \n",
       "0            6     0        0     0        0  \n",
       "1            0     1        0    11        1  \n",
       "2           17     3        0     4        0  \n",
       "3            3     0        0     0        0  \n",
       "4           22     0        0     0        0  \n",
       "5            4     4        0     0        0  \n",
       "6            2     5        0     0        2  \n",
       "7            6     4        0    15        0  \n",
       "8            3    11        0     1        0  \n",
       "9            0     2        2     0        1  \n",
       "10           2     7       13     7       15  \n",
       "11           4     5        9     0       10  \n",
       "12           0     0        0     0        0  \n",
       "13           3     2        0     3        0  \n",
       "14           8     4        0     3        0  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df1['k'], df1['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It appears that belles lettres are not being clustered together.  This could be because belles lettres is\n",
    "# considered more of a writing style than a genre.  \n",
    "# Make a DataFrame that drops belles lettres and rerun the clustering.\n",
    "\n",
    "df_nobell = df1\n",
    "df_nobell = df_nobell[df_nobell.genre != 'belles_lettres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try the clusters using the DataFrame that does not inclue science fiction, humor, reviews or religion--\n",
    "# df1\n",
    "\n",
    "genre_nobell = df_nobell.genre\n",
    "true_k_nobell = np.unique(genre_nobell).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the text in the new DataFrame--use the vectorizer that we use in Unsupervised learning\n",
    "X_nobell = vectorizer.fit_transform(df_nobell['text'])\n",
    "\n",
    "# Fit the kmeans cluster\n",
    "fit_nobell = km.fit(X_nobell)\n",
    "\n",
    "# Assign the labels to a column in the new DataFrame\n",
    "labels_nobell = km.labels_\n",
    "df_nobell['k'] = labels_nobell\n",
    "\n",
    "# Find the cluster centers\n",
    "centers_nobell = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35172659547154828"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(genre_nobell, labels_nobell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32871192653160475"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(genre_nobell, labels_nobell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33983004509941395"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(genre_nobell, labels_nobell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13750381826279781"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(genre_nobell, labels_nobell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>adventure</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>mystery</th>\n",
       "      <th>news</th>\n",
       "      <th>romance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  adventure  editorial  fiction  government  hobbies  learned  lore  \\\n",
       "k                                                                          \n",
       "0              0          0        0           0        0       10     0   \n",
       "1             12          0        9           1        7        5     6   \n",
       "2              0          1        2           0        1        3     3   \n",
       "3              1          3        0           0        0        2     2   \n",
       "4              2          1        4           0        3        1     5   \n",
       "5              0         15        0           4        2        3     6   \n",
       "6              0          0        0           5        6       10     1   \n",
       "7              0          0        1           5        2        1     2   \n",
       "8              0          0        0           1        9       20     2   \n",
       "9              0          0        1           1        0        4     5   \n",
       "10             0          2        0           6        3        2     3   \n",
       "11             0          1        0           0        1       14     8   \n",
       "12             0          1        0           7        1        2     2   \n",
       "13             8          1        4           0        1        1     0   \n",
       "14             6          2        8           0        0        2     3   \n",
       "\n",
       "genre  mystery  news  romance  \n",
       "k                              \n",
       "0            0     0        0  \n",
       "1            2     0        4  \n",
       "2            3    11        1  \n",
       "3            0     7        0  \n",
       "4            0     7        3  \n",
       "5            0     6        0  \n",
       "6            0     2        0  \n",
       "7            0     1        1  \n",
       "8            0     0        0  \n",
       "9            0     1        0  \n",
       "10           0     8        0  \n",
       "11           0     0        0  \n",
       "12           0     1        0  \n",
       "13          12     0        4  \n",
       "14           7     0       16  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_nobell['k'], df_nobell['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So dropping belles_letters did not work well either; I will keep belle_lettres out of\n",
    "# the DataFrame and combine fiction, adventure, mystery, and romance.\n",
    "\n",
    "df_last = df2\n",
    "df_last = df_last[df_last.genre != 'belles_lettres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_last = df_last.genre\n",
    "true_k_last = np.unique(genre_last).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the text in the new DataFrame--use the vectorizer that we use in Unsupervised learning\n",
    "X_last = vectorizer.fit_transform(df_last['text'])\n",
    "\n",
    "# Fit the kmeans cluster\n",
    "fit_last = km.fit(X_last)\n",
    "\n",
    "# Assign the labels to a column in the new DataFrame\n",
    "labels_last = km.labels_\n",
    "df_last['k'] = labels_last\n",
    "\n",
    "# Find the cluster centers\n",
    "centers_last = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37746299541319928"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(genre_last, labels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27747858178281504"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(genre_last, labels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31983889949744709"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(genre_last, labels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23010997503030736"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(genre_last, labels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  editorial  fiction  government  hobbies  learned  lore  news\n",
       "k                                                                  \n",
       "0              0        0           0        3        4     2     0\n",
       "1              1        0          11       11       13     2     4\n",
       "2              1        1           1        2        8     1     2\n",
       "3              0        2           1        2        7     8     1\n",
       "4              0        3           0        0        0     0     0\n",
       "5              3        0           9        1        6     7     0\n",
       "6              0        0           0        2        0     1     7\n",
       "7              0        0           1        3       21     0     0\n",
       "8              0       29           0        1        1     1     0\n",
       "9              0       12           0        4        1     7     0\n",
       "10             4        0           2        0        4     2    14\n",
       "11            13        0           2        2        2     5    10\n",
       "12             0        3           1        1        0     2     0\n",
       "13             1        0           2        1       10     5     0\n",
       "14             4       61           0        3        3     5     6"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_last['k'], df_last['genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering worked better when I removed belles_lettres from the list of genres, so I am going to try unsupervised learning without it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_nb = df_nobell['text']\n",
    "genre_nb = df_nobell['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 15598\n",
      "Number of features: 15598\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train_nb, text_test_nb, categories_train_nb, categories_test_nb = train_test_split(\n",
    "    text_nb, genre_nb, test_size=0.25, random_state=42, stratify=genre_nb)\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf_nb = vectorizer.fit_transform(text_train_nb)\n",
    "print(\"Number of features: %d\" % train_tfidf_nb.get_shape()[1])\n",
    "\n",
    "test_tfidf_nb = vectorizer.transform(text_test_nb)\n",
    "print(\"Number of features: %d\" % test_tfidf_nb.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.39361702127659576\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "fit_nb = rfc.fit(train_tfidf_nb, categories_train_nb)\n",
    "predict_nb = rfc.predict(test_tfidf_nb)\n",
    "score_nb = rfc.score(test_tfidf_nb, categories_test_nb)\n",
    "\n",
    "print('Random Forest Classifier Score: {}'.format(score_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.36220472  0.33070866  0.26229508]\n",
      "Accuracy: 0.32 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validate\n",
    "\n",
    "cvs_rfc_nb = cross_val_score(rfc, X_nobell, genre_nb)\n",
    "print('Cross Validated Scores: {}'.format(cvs_rfc_nb))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_rfc_nb.mean(), cvs_rfc_nb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier Score: 0.4787234042553192\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "fit_nb_svc = svc.fit(train_tfidf_nb, categories_train_nb)\n",
    "predict_nb_svc = svc.predict(test_tfidf_nb)\n",
    "score_nb_svc = svc.score(test_tfidf_nb, categories_test_nb)\n",
    "\n",
    "print('Support Vector Machine Classifier Score: {}'.format(score_nb_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.51181102  0.45669291  0.36885246]\n",
      "Accuracy: 0.45 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validate\n",
    "\n",
    "cvs_svc_nb = cross_val_score(svc, X_nobell, genre_nb)\n",
    "print('Cross Validated Scores: {}'.format(cvs_svc_nb))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_svc_nb.mean(), cvs_svc_nb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.3723404255319149\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "fit_nb_lr = lr.fit(train_tfidf_nb, categories_train_nb)\n",
    "predict_nb_lr = lr.predict(test_tfidf_nb)\n",
    "score_nb_lr = lr.score(test_tfidf_nb, categories_test_nb)\n",
    "\n",
    "print('Logistic Regression Score: {}'.format(score_nb_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score: 0.3829787234042553\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "\n",
    "\n",
    "fit_nb_gbc = gbc.fit(train_tfidf_nb.toarray(), categories_train_nb)\n",
    "predict_nb_gbc = gbc.predict(test_tfidf_nb.toarray())\n",
    "score_nb_gbc = gbc.score(test_tfidf_nb.toarray(), categories_test_nb)\n",
    "\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score_nb_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No belles letters and combined fiction adventure mystery and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_last = df_last['text']\n",
    "genre_last = df_last['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 15598\n",
      "Number of features: 15598\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train_last, text_test_last, categories_train_last, categories_test_last = train_test_split(\n",
    "    text_last, genre_last, test_size=0.25, random_state=42, stratify=genre_nb)\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf_last = vectorizer.fit_transform(text_train_last)\n",
    "print(\"Number of features: %d\" % train_tfidf_last.get_shape()[1])\n",
    "\n",
    "test_tfidf_last = vectorizer.transform(text_test_last)\n",
    "print(\"Number of features: %d\" % test_tfidf_last.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.5212765957446809\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "fit_last = rfc.fit(train_tfidf_last, categories_train_last)\n",
    "predict_last = rfc.predict(test_tfidf_last)\n",
    "score_last = rfc.score(test_tfidf_last, categories_test_last)\n",
    "\n",
    "print('Random Forest Classifier Score: {}'.format(score_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier Score: 0.6276595744680851\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "fit_last_svc = svc.fit(train_tfidf_last, categories_train_last)\n",
    "predict_last_svc = svc.predict(test_tfidf_last)\n",
    "score_last_svc = svc.score(test_tfidf_last, categories_test_last)\n",
    "\n",
    "print('Support Vector Machine Classifier Score: {}'.format(score_last_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.5425531914893617\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "fit_last_lr = lr.fit(train_tfidf_last, categories_train_last)\n",
    "predict_last_lr = lr.predict(test_tfidf_last)\n",
    "score_last_lr = lr.score(test_tfidf_last, categories_test_last)\n",
    "\n",
    "print('Logistic Regression Score: {}'.format(score_last_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.5531914893617021\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "fit_last_knn = knn.fit(train_tfidf_last, categories_train_last)\n",
    "predict_last_knn = knn.predict(test_tfidf_last)\n",
    "score_last_knn = knn.score(test_tfidf_last, categories_test_last)\n",
    "\n",
    "print('Logistic Regression Score: {}'.format(score_last_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the unsupervised work that I did first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "text_train, text_test, categories_train, categories_test = train_test_split(\n",
    "    text, categories, test_size=0.25, random_state=42, stratify=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learned            20\n",
       "belles_lettres     19\n",
       "lore               12\n",
       "news               11\n",
       "hobbies             9\n",
       "government          8\n",
       "fiction             7\n",
       "romance             7\n",
       "editorial           7\n",
       "adventure           7\n",
       "mystery             6\n",
       "religion            4\n",
       "reviews             4\n",
       "science_fiction     2\n",
       "humor               2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(categories_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 18959\n",
      "Number of features: 18959\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.tfidfvectorizer to vectorize the data\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf=vectorizer.fit_transform(text_train)\n",
    "print(\"Number of features: %d\" % train_tfidf.get_shape()[1])\n",
    "\n",
    "test_tfidf = vectorizer.transform(text_test)\n",
    "print(\"Number of features: %d\" % test_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit = rfc.fit(train_tfidf, categories_train)\n",
    "predict = rfc.predict(test_tfidf)\n",
    "score = rfc.score(test_tfidf, categories_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text = vectorizer.fit_transform(text)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_rfc = cross_val_score(rfc, vector_text, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.31360947  0.25443787  0.29012346]\n",
      "Accuracy: 0.29 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc.mean(), cross_val_rfc.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are pretty awful.  I am going to analyze the data to see where the models are making mistakes and then adjust the data hopefully make the models more accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned            80\n",
      "belles_lettres     75\n",
      "lore               48\n",
      "news               44\n",
      "hobbies            36\n",
      "government         30\n",
      "fiction            29\n",
      "romance            29\n",
      "adventure          29\n",
      "editorial          27\n",
      "mystery            24\n",
      "religion           17\n",
      "reviews            17\n",
      "humor               9\n",
      "science_fiction     6\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine how many titles are in each genre\n",
    "\n",
    "print(df['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned           80\n",
      "belles_lettres    75\n",
      "lore              48\n",
      "news              44\n",
      "hobbies           36\n",
      "government        30\n",
      "fiction           29\n",
      "romance           29\n",
      "adventure         29\n",
      "editorial         27\n",
      "mystery           24\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We will drop the bottom four genres because there are not enough titles to adequately\n",
    "# train the models to recognize them\n",
    "\n",
    "df1 = df # create a new DataFrame\n",
    "\n",
    "\n",
    "drop_list = ['science_fiction', 'humor', 'reviews', 'religion']\n",
    "for each in drop_list:\n",
    "    df1 = df1[df1.genre != each]\n",
    "\n",
    "print(df1['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for the text and genre in the new DataFrame\n",
    "text1 = df1['text']\n",
    "categories1 = df1['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train1, text_test1, categories_train1, categories_test1 = train_test_split(\n",
    "    text1, categories1, test_size=0.25, random_state=42, stratify=categories1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17616\n",
      "Number of features: 17616\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf1 = vectorizer.fit_transform(text_train1)\n",
    "print(\"Number of features: %d\" % train_tfidf1.get_shape()[1])\n",
    "\n",
    "test_tfidf1 = vectorizer.transform(text_test1)\n",
    "print(\"Number of features: %d\" % test_tfidf1.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit1 = rfc.fit(train_tfidf1, categories_train1)\n",
    "predict1 = rfc.predict(test_tfidf1)\n",
    "score1 = rfc.score(test_tfidf1, categories_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.40707964601769914\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text1 = vectorizer.fit_transform(text1)\n",
    "\n",
    "cross_val_rfc1 = cross_val_score(rfc, vector_text1, categories1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.34210526  0.30263158  0.27891156]\n",
      "Accuracy: 0.31 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc1.mean(), cross_val_rfc1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the model has gotten fractionally better, but it is still pretty awful.  After further examination of the clustered data above, it appears that adventure, fiction, mystery, and romance are frequently clustered together.  We will combine those categories under the genre 'fiction' and rerun the model and hope for increased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction           111\n",
      "learned            80\n",
      "belles_lettres     75\n",
      "lore               48\n",
      "news               44\n",
      "hobbies            36\n",
      "government         30\n",
      "editorial          27\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame\n",
    "\n",
    "df2 = df1\n",
    "\n",
    "# Rename all adventure, mystery, and romance titles\n",
    "replace_list = ['adventure', 'mystery', 'romance']\n",
    "for each in replace_list:\n",
    "    df2 = df2.replace(each, 'fiction')\n",
    "\n",
    "print(df2['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables for the text and genre in the new DataFrame\n",
    "text2 = df2['text']\n",
    "categories2 = df2['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train2, text_test2, categories_train2, categories_test2 = train_test_split(\n",
    "    text2, categories2, test_size=0.25, random_state=42, stratify=categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf2 = vectorizer.fit_transform(text_train2)\n",
    "print(\"Number of features: %d\" % train_tfidf2.get_shape()[1])\n",
    "\n",
    "test_tfidf2 = vectorizer.transform(text_test2)\n",
    "print(\"Number of features: %d\" % test_tfidf2.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 338\n",
      "Number of Rows: 113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of Rows: %d\" % train_tfidf2.get_shape()[0])\n",
    "\n",
    "print(\"Number of Rows: %d\" % test_tfidf2.get_shape()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "fit2 = rfc.fit(train_tfidf2, categories_train2)\n",
    "predict2 = rfc.predict(test_tfidf2)\n",
    "score2 = rfc.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.48672566371681414\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text2 = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_rfc2 = cross_val_score(rfc, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.53642384  0.43046358  0.4966443 ]\n",
      "Accuracy: 0.49 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc2.mean(), cross_val_rfc2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "fit2_svc = svc.fit(train_tfidf2, categories_train2)\n",
    "predict2_svc = svc.predict(test_tfidf2)\n",
    "score2_svc = svc.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63716814159292035"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "fit_gbc2 = gbc.fit(train_tfidf2.toarray(), categories_train2)\n",
    "predict_gbc2 = gbc.predict(test_tfidf2.toarray())\n",
    "score_gbc2 = gbc.score(test_tfidf2.toarray(), categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53097345132743368"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_gbc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining adventure, fiction, mystery, and romance resulted in greatly increased model, however the model is still under fifty percent accurate.  More improvements need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try adding a stemmer and tokenizer to the vectorizer.\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    # strip out punctuation and make lowercase\n",
    "    tokens = [token.lower().strip(string.punctuation)\n",
    "             for token in tokens if token.isalnum()]\n",
    "    \n",
    "    # now stem the tokens\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the tokenize_and_stem function to the vectorizer\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True, #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                             tokenizer = tokenize_and_stem\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf3 = vectorizer2.fit_transform(text_train2)\n",
    "print(\"Number of features: %d\" % train_tfidf2.get_shape()[1])\n",
    "\n",
    "test_tfidf3 = vectorizer2.transform(text_test2)\n",
    "print(\"Number of features: %d\" % test_tfidf2.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "fit3 = rfc.fit(train_tfidf3, categories_train2)\n",
    "predict3 = rfc.predict(test_tfidf3)\n",
    "score3 = rfc.score(test_tfidf3, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text3 = vectorizer2.fit_transform(text2)\n",
    "\n",
    "cross_val_rfc3 = cross_val_score(rfc, vector_text3, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.53642384  0.40397351  0.48322148]\n",
      "Accuracy: 0.47 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc3))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc3.mean(), cross_val_rfc3.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "fit3_svc = svc.fit(train_tfidf3, categories_train2)\n",
    "predict3_svc = svc.predict(test_tfidf3)\n",
    "score3_svc = svc.score(test_tfidf3, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63716814159292035"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the tokenize_and_stem function to the vectorizer actually made the model worse.  Looks like I need to find another solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try different supervised learning models and see if we can find a more accurate model\n",
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a support vector machine classifier\n",
    "\n",
    "svc = SVC(kernel = 'linear')\n",
    "\n",
    "fit_svc = svc.fit(train_tfidf2, categories_train2)\n",
    "predict_svc = svc.predict(test_tfidf2)\n",
    "score_svc = svc.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Score: 0.6371681415929203\n"
     ]
    }
   ],
   "source": [
    "print('Support Vector Classifier Score: {}'.format(score_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_svc = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_svc = cross_val_score(svc, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.62913907  0.53642384  0.55704698]\n",
      "Accuracy: 0.57 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_svc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_svc.mean(), cross_val_svc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit_lr = lr.fit(train_tfidf2, categories_train2)\n",
    "predict_lr = lr.predict(test_tfidf2)\n",
    "score_lr = lr.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Score: {}'.format(score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_lr = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_lr = cross_val_score(lr, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.52980132  0.42384106  0.46308725]\n",
      "Accuracy: 0.47 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_lr))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_lr.mean(), cross_val_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a K Nearest Neighbors Classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "fit_knn = knn.fit(train_tfidf2, categories_train2)\n",
    "predict_knn = knn.predict(test_tfidf2)\n",
    "score_knn = knn.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.6460176991150443\n"
     ]
    }
   ],
   "source": [
    "print('KNN Classifier Score: {}'.format(score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_knn = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_knn = cross_val_score(knn, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.60927152  0.52980132  0.52348993]\n",
      "Accuracy: 0.55 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_knn))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_knn.mean(), cross_val_knn.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n",
      "Gradient Boosting Classifier Score: 0.5486725663716814\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "# Create variables for the text and genre in the new DataFrame\n",
    "text2_gbc = df2['text']\n",
    "categories2_gbc = df2['genre']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "text_train2_gbc, text_test2_gbc, categories_train2_gbc, categories_test2_gbc = train_test_split(\n",
    "    text2_gbc, categories2_gbc, test_size=0.25, random_state=42, stratify=categories2_gbc)\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf2_gbc = vectorizer.fit_transform(text_train2_gbc)\n",
    "print(\"Number of features: %d\" % train_tfidf2_gbc.get_shape()[1])\n",
    "\n",
    "test_tfidf2_gbc = vectorizer.transform(text_test2_gbc)\n",
    "print(\"Number of features: %d\" % test_tfidf2_gbc.get_shape()[1])\n",
    "\n",
    "# Run GBC\n",
    "fit_gbc = gbc.fit(train_tfidf2_gbc.toarray(), categories_train2_gbc)\n",
    "predict_gbc = gbc.predict(test_tfidf2_gbc.toarray())\n",
    "score_gbc = gbc.score(test_tfidf2_gbc.toarray(), categories_test2_gbc)\n",
    "\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_gbc = vectorizer.fit_transform(text2_gbc)\n",
    "\n",
    "cross_val_gbc = cross_val_score(gbc, vector_text_gbc.toarray(), categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.53642384  0.53642384  0.41610738]\n",
      "Accuracy: 0.50 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_gbc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_gbc.mean(), cross_val_gbc.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supervised model that outputted the best results using the vectorized data was the KNN Classifier with a score of 0.646 and a cross-validated score of 0.55 (+/- 0.08).  However, this is still a very poorly performing model.  In order to try to continue to improve the performance of the models, I am going to add more features using the bag-of-words method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 10 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(11)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = []\n",
    "for each in rar_list1:\n",
    "    w = bag_of_words(each)\n",
    "    for words in w:\n",
    "        common_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3157"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = set(common_words)\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fiction           111\n",
       "learned            80\n",
       "belles_lettres     75\n",
       "lore               48\n",
       "news               44\n",
       "hobbies            36\n",
       "government         30\n",
       "editorial          27\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames that isolate texts be genre\n",
    "\n",
    "# fiction\n",
    "df_fic = df2\n",
    "df_fic = df_fic[df_fic.genre == 'fiction' ]\n",
    "\n",
    "# learned\n",
    "df_learn = df2\n",
    "df_learn = df_learn[df_learn.genre == 'learned']\n",
    "\n",
    "# belles_lettres\n",
    "df_bell = df2\n",
    "df_bell = df_bell[df_bell.genre == 'belles_lettres']\n",
    "\n",
    "# lore\n",
    "df_lore = df2\n",
    "df_lore = df_lore[df_lore.genre == 'lore']\n",
    "\n",
    "# news\n",
    "df_news = df2\n",
    "df_news = df_news[df_news.genre == 'news']\n",
    "\n",
    "# hobbies\n",
    "df_hob = df2\n",
    "df_hob = df_hob[df_hob.genre == 'hobbies']\n",
    "\n",
    "# government\n",
    "df_gov = df2\n",
    "df_gov = df_gov[df_gov.genre == 'government']\n",
    "\n",
    "# editorial\n",
    "df_ed = df2\n",
    "df_ed = df_ed[df_ed.genre == 'editorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Remove the `` from the text because it pops up as one of the most common words for each\n",
    "# genre.\n",
    "# Combine all the texts from each genre. Parse each newly created text.\n",
    "\n",
    "df_fic['text'] = df_fic['text'].str.replace('``', '')\n",
    "fiction = ''.join(df_fic['text'].tolist())\n",
    "fiction = nlp(fiction)\n",
    "\n",
    "df_learn['text'] = df_learn['text'].str.replace('``', '')\n",
    "learned = ''.join(df_learn['text'].tolist())\n",
    "learned = nlp(learned)\n",
    "\n",
    "df_bell['text'] = df_bell['text'].str.replace('``', '')\n",
    "belles = ''.join(df_bell['text'].tolist())\n",
    "belles = nlp(belles)\n",
    "\n",
    "#lore\n",
    "df_lore['text'] = df_lore['text'].str.replace('``', '')\n",
    "lore = ''.join(df_lore['text'].tolist())\n",
    "lore = nlp(lore)\n",
    "\n",
    "# news\n",
    "df_news['text'] = df_news['text'].str.replace('``', '')\n",
    "news = ''.join(df_news['text'].tolist())\n",
    "news = nlp(news)\n",
    "\n",
    "#hob\n",
    "df_hob['text'] = df_hob['text'].str.replace('``', '')\n",
    "hobbies = ''.join(df_hob['text'].tolist())\n",
    "hobbies = nlp(hobbies)\n",
    "\n",
    "df_gov['text'] = df_gov['text'].str.replace('``', '')\n",
    "government= ''.join(df_gov['text'].tolist())\n",
    "government = nlp(government)\n",
    "\n",
    "df_ed['text'] = df_ed['text'].str.replace('``', '')\n",
    "editorial = ''.join(df_ed['text'].tolist())\n",
    "editorial = nlp(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the parsed texts through the bag-of-words function to find the most common words\n",
    "# for each genre.\n",
    "\n",
    "fiction_bow = bag_of_words(fiction)\n",
    "learned_bow = bag_of_words(learned)\n",
    "belles_bow = bag_of_words(belles)\n",
    "lore_bow = bag_of_words(lore)\n",
    "news_bow = bag_of_words(news)\n",
    "hobbies_bow = bag_of_words(hobbies)\n",
    "government_bow = bag_of_words(government)\n",
    "editorial_bow = bag_of_words(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the bags to create a set of unique words\n",
    "\n",
    "common_words = set(fiction_bow + learned_bow + belles_bow + lore_bow + news_bow + hobbies_bow + government_bow + editorial_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Parse each of the texts individually\n",
    "\n",
    "# Fiction\n",
    "rar_list = []\n",
    "for each in df_fic['text']:\n",
    "    rar_list.append(each)\n",
    "rar_list1 = []\n",
    "for each in rar_list:\n",
    "    t = nlp(each)\n",
    "    rar_list1.append(t)\n",
    "df_fic['text'] = rar_list1\n",
    "\n",
    "# Learned\n",
    "star_list = []\n",
    "for each in df_learn['text']:\n",
    "    star_list.append(each)\n",
    "sun_list = []\n",
    "for each in star_list:\n",
    "    t = nlp(each)\n",
    "    sun_list.append(t)\n",
    "df_learn['text'] = sun_list\n",
    "\n",
    "# Belles Lettres\n",
    "star_list1 = []\n",
    "for each in df_bell['text']:\n",
    "    star_list1.append(each)\n",
    "sun_list1 = []\n",
    "for each in star_list1:\n",
    "    t = nlp(each)\n",
    "    sun_list1.append(t)\n",
    "df_bell['text'] = sun_list1\n",
    "\n",
    "# Lore\n",
    "star_list2 = []\n",
    "for each in df_lore['text']:\n",
    "    star_list2.append(each)\n",
    "sun_list2 = []\n",
    "for each in star_list2:\n",
    "    t = nlp(each)\n",
    "    sun_list2.append(t)\n",
    "df_lore['text'] = sun_list2\n",
    "\n",
    "# News\n",
    "star_list3 = []\n",
    "for each in df_news['text']:\n",
    "    star_list3.append(each)\n",
    "sun_list3 = []\n",
    "for each in star_list3:\n",
    "    t = nlp(each)\n",
    "    sun_list3.append(t)\n",
    "df_news['text'] = sun_list3\n",
    "\n",
    "# Hobbies\n",
    "star_list4 = []\n",
    "for each in df_hob['text']:\n",
    "    star_list4.append(each)\n",
    "sun_list4 = []\n",
    "for each in star_list4:\n",
    "    t = nlp(each)\n",
    "    sun_list4.append(t)\n",
    "df_hob['text'] = sun_list4\n",
    "\n",
    "# Government\n",
    "star_list5 = []\n",
    "for each in df_gov['text']:\n",
    "    star_list5.append(each)\n",
    "sun_list5 = []\n",
    "for each in star_list5:\n",
    "    t = nlp(each)\n",
    "    sun_list5.append(t)\n",
    "df_gov['text'] = sun_list5\n",
    "\n",
    "# Editorials\n",
    "star_list6 = []\n",
    "for each in df_ed['text']:\n",
    "    star_list6.append(each)\n",
    "sun_list6 = []\n",
    "for each in star_list6:\n",
    "    t = nlp(each)\n",
    "    sun_list6.append(t)\n",
    "df_ed['text'] = sun_list6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_fic, df_learn, df_bell, df_lore, df_news, df_hob, df_gov, df_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['index'] = df_new.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "      <th>k</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ck01</td>\n",
       "      <td>(thirty, -, three, scotty, did, not, go, back,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ck02</td>\n",
       "      <td>(where, their, sharp, edges, seemed, restless,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ck03</td>\n",
       "      <td>(mickie, sat, over, his, second, whisky, -, on...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ck04</td>\n",
       "      <td>(the, bishop, looked, at, him, coldly, and, sa...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ck05</td>\n",
       "      <td>(payne, dismounted, in, madison, place, and, h...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ck06</td>\n",
       "      <td>(with, a, sneer, ,, the, man, spread, his, leg...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ck07</td>\n",
       "      <td>(if, the, crummy, bastard, could, write, !, !,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ck08</td>\n",
       "      <td>(rousseau, is, so, persuasive, that, voltaire,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ck09</td>\n",
       "      <td>(it, was, the, first, time, any, of, us, had, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ck10</td>\n",
       "      <td>(that, summer, the, gambling, houses, were, cl...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ck11</td>\n",
       "      <td>(standing, in, the, shelter, of, the, tent, --...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ck12</td>\n",
       "      <td>(she, was, a, child, too, much, a, part, of, h...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ck13</td>\n",
       "      <td>(in, the, dim, underwater, light, they, dresse...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ck14</td>\n",
       "      <td>(he, brought, with, him, a, mixture, of, myrrh...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ck15</td>\n",
       "      <td>(beth, was, very, still, and, her, breath, cam...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ck16</td>\n",
       "      <td>(the, red, glow, from, the, cove, had, died, o...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ck17</td>\n",
       "      <td>(burly, leathered, men, and, wrinkled, women, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ck18</td>\n",
       "      <td>(she, was, getting, real, dramatic, ., i, 'd, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ck19</td>\n",
       "      <td>(there, was, one, fact, which, rector, could, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ck20</td>\n",
       "      <td>(she, concluded, by, asking, him, to, name, an...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                               text    genre   k  \\\n",
       "0   ck01  (thirty, -, three, scotty, did, not, go, back,...  fiction   0   \n",
       "1   ck02  (where, their, sharp, edges, seemed, restless,...  fiction  13   \n",
       "2   ck03  (mickie, sat, over, his, second, whisky, -, on...  fiction   0   \n",
       "3   ck04  (the, bishop, looked, at, him, coldly, and, sa...  fiction   8   \n",
       "4   ck05  (payne, dismounted, in, madison, place, and, h...  fiction   0   \n",
       "5   ck06  (with, a, sneer, ,, the, man, spread, his, leg...  fiction   8   \n",
       "6   ck07  (if, the, crummy, bastard, could, write, !, !,...  fiction   0   \n",
       "7   ck08  (rousseau, is, so, persuasive, that, voltaire,...  fiction   1   \n",
       "8   ck09  (it, was, the, first, time, any, of, us, had, ...  fiction  13   \n",
       "9   ck10  (that, summer, the, gambling, houses, were, cl...  fiction   8   \n",
       "10  ck11  (standing, in, the, shelter, of, the, tent, --...  fiction  13   \n",
       "11  ck12  (she, was, a, child, too, much, a, part, of, h...  fiction   0   \n",
       "12  ck13  (in, the, dim, underwater, light, they, dresse...  fiction   0   \n",
       "13  ck14  (he, brought, with, him, a, mixture, of, myrrh...  fiction   0   \n",
       "14  ck15  (beth, was, very, still, and, her, breath, cam...  fiction   0   \n",
       "15  ck16  (the, red, glow, from, the, cove, had, died, o...  fiction  13   \n",
       "16  ck17  (burly, leathered, men, and, wrinkled, women, ...  fiction   0   \n",
       "17  ck18  (she, was, getting, real, dramatic, ., i, 'd, ...  fiction   0   \n",
       "18  ck19  (there, was, one, fact, which, rector, could, ...  fiction   0   \n",
       "19  ck20  (she, concluded, by, asking, him, to, name, an...  fiction   0   \n",
       "\n",
       "    index  \n",
       "0     374  \n",
       "1     375  \n",
       "2     376  \n",
       "3     377  \n",
       "4     378  \n",
       "5     379  \n",
       "6     380  \n",
       "7     381  \n",
       "8     382  \n",
       "9     383  \n",
       "10    384  \n",
       "11    385  \n",
       "12    386  \n",
       "13    387  \n",
       "14    388  \n",
       "15    389  \n",
       "16    390  \n",
       "17    391  \n",
       "18    392  \n",
       "19    393  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df_bow = pd.DataFrame(columns=common_words)\n",
    "    df_bow['text'] = df_new['text']\n",
    "    df_bow.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, corp in enumerate(df_bow['text']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in corp\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df_bow.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mr</th>\n",
       "      <th>not</th>\n",
       "      <th>world</th>\n",
       "      <th>1</th>\n",
       "      <th>think</th>\n",
       "      <th>point</th>\n",
       "      <th>new</th>\n",
       "      <th>mrs</th>\n",
       "      <th>president</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>school</th>\n",
       "      <th>have</th>\n",
       "      <th>system</th>\n",
       "      <th>like</th>\n",
       "      <th>look</th>\n",
       "      <th>come</th>\n",
       "      <th>people</th>\n",
       "      <th>2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(thirty, -, three, scotty, did, not, go, back,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(where, their, sharp, edges, seemed, restless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(mickie, sat, over, his, second, whisky, -, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>(the, bishop, looked, at, him, coldly, and, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(payne, dismounted, in, madison, place, and, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  year mr not world  1 think point new mrs president  \\\n",
       "0    0  6   5     0  0     6     0   1   1         0   \n",
       "1    0  0   6     0  0     4     4   3   0         0   \n",
       "2    1  2  12     1  0     4     1   2   3         9   \n",
       "3    8  0   5     0  0     3     0   4   2         0   \n",
       "4    0  1   3     2  0     2     1   2   4         1   \n",
       "\n",
       "                         ...                         place school have system  \\\n",
       "0                        ...                             0      6   27      0   \n",
       "1                        ...                             3      0   13      0   \n",
       "2                        ...                             1      1   14      0   \n",
       "3                        ...                             6      1    2      1   \n",
       "4                        ...                             1      0   10      0   \n",
       "\n",
       "  like look come people  2                                               text  \n",
       "0    6   10    5      0  0  (thirty, -, three, scotty, did, not, go, back,...  \n",
       "1    9    3    4      2  0  (where, their, sharp, edges, seemed, restless,...  \n",
       "2    9    6    7      1  1  (mickie, sat, over, his, second, whisky, -, on...  \n",
       "3    7   10    3      6  0  (the, bishop, looked, at, him, coldly, and, sa...  \n",
       "4    9    4    2      2  0  (payne, dismounted, in, madison, place, and, h...  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts['index'] = df_new['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts['genre'] = df_new['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec = vectorizer.fit_transform(df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<451x20647 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 240774 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.1040955   0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.03386396  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(text_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0\n"
     ]
    }
   ],
   "source": [
    "list_ = ['a'+str(i) for i in range(20647)]\n",
    "print(list_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vec = pd.DataFrame(text_vec.toarray(), columns = list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>...</th>\n",
       "      <th>a20637</th>\n",
       "      <th>a20638</th>\n",
       "      <th>a20639</th>\n",
       "      <th>a20640</th>\n",
       "      <th>a20641</th>\n",
       "      <th>a20642</th>\n",
       "      <th>a20643</th>\n",
       "      <th>a20644</th>\n",
       "      <th>a20645</th>\n",
       "      <th>a20646</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a0        a1   a2   a3   a4   a5   a6   a7   a8        a9   ...    a20637  \\\n",
       "0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.010579   ...       0.0   \n",
       "1  0.0  0.104096  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.011233   ...       0.0   \n",
       "2  0.0  0.033864  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.076740   ...       0.0   \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000   ...       0.0   \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.025149   ...       0.0   \n",
       "\n",
       "   a20638  a20639  a20640  a20641  a20642  a20643  a20644  a20645  a20646  \n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 20647 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vec['index'] = df_vec.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>...</th>\n",
       "      <th>school</th>\n",
       "      <th>have</th>\n",
       "      <th>system</th>\n",
       "      <th>like</th>\n",
       "      <th>look</th>\n",
       "      <th>come</th>\n",
       "      <th>people</th>\n",
       "      <th>2</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(the, fulton, county, grand, jury, said, frida...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(austin, ,, texas, --, committee, approval, of...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(several, defendants, in, the, summerdale, pol...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(oslo, the, most, positive, element, to, emerg...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(east, providence, should, organize, its, civi...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20693 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a0        a1   a2   a3   a4   a5   a6   a7   a8        a9  ...    school  \\\n",
       "0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.010579  ...         5   \n",
       "1  0.0  0.104096  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.011233  ...        19   \n",
       "2  0.0  0.033864  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.076740  ...         9   \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...         0   \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.025149  ...         0   \n",
       "\n",
       "   have  system  like  look  come  people  2  \\\n",
       "0    19       2     2     0     0       0  3   \n",
       "1    11       0     3     0     1       3  0   \n",
       "2     9       3     0     0     0       3  1   \n",
       "3    10       1     0     1     2       0  0   \n",
       "4     8       2     0     0     7       1  0   \n",
       "\n",
       "                                                text  genre  \n",
       "0  (the, fulton, county, grand, jury, said, frida...   news  \n",
       "1  (austin, ,, texas, --, committee, approval, of...   news  \n",
       "2  (several, defendants, in, the, summerdale, pol...   news  \n",
       "3  (oslo, the, most, positive, element, to, emerg...   news  \n",
       "4  (east, providence, should, organize, its, civi...   news  \n",
       "\n",
       "[5 rows x 20693 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.merge(df_vec, word_counts, how='inner', on='index')\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create target and predictor variables; normalize the predictor variables\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "features = word_counts.drop(['text', 'genre', 'index'], axis=1)\n",
    "features = normalize(features)\n",
    "target_var = word_counts['genre']\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "feat_train, feat_test, genre_train, genre_test = train_test_split(\n",
    "    features, target_var, test_size=0.25, random_state=0, stratify=target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.47572815533980584\n"
     ]
    }
   ],
   "source": [
    "# Run the supervised models on the DataFrame---\n",
    "# Random Forest, Support Vector Machine, Logistic Regression, KNN\n",
    "\n",
    "# Random Forest\n",
    "fit = rfc.fit(feat_train, genre_train)\n",
    "predict = rfc.predict(feat_test)\n",
    "score = rfc.score(feat_test, genre_test)\n",
    "\n",
    "print('Random Forest Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.34057971  0.4057971   0.31851852]\n",
      "Accuracy: 0.35 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "\n",
    "cvs_rfc = cross_val_score(rfc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_rfc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_rfc.mean(), cvs_rfc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Score: 0.5922330097087378\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "fit = svc.fit(feat_train, genre_train)\n",
    "predict = svc.predict(feat_test)\n",
    "score = svc.score(feat_test, genre_test)\n",
    "\n",
    "print('Support Vector Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.5942029   0.46376812  0.47407407]\n",
      "Accuracy: 0.51 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cvs_svc = cross_val_score(svc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_svc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_svc.mean(), cvs_svc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.6116504854368932\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "fit = lr.fit(feat_train, genre_train)\n",
    "predict = lr.predict(feat_test)\n",
    "score = lr.score(feat_test, genre_test)\n",
    "\n",
    "print('Logistic Regression Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.56521739  0.42753623  0.47407407]\n",
      "Accuracy: 0.49 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cvs_lr = cross_val_score(lr, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_lr))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_lr.mean(), cvs_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.5145631067961165\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "fit = knn.fit(feat_train, genre_train)\n",
    "predict = knn.predict(feat_test)\n",
    "score = knn.score(feat_test, genre_test)\n",
    "\n",
    "print('KNN Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.54347826  0.39855072  0.42222222]\n",
      "Accuracy: 0.45 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cvs_knn = cross_val_score(knn, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_knn))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_knn.mean(), cvs_knn.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score: 0.5631067961165048\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "fit = gbc.fit(feat_train, genre_train)\n",
    "predict = gbc.predict(feat_test)\n",
    "score = gbc.score(feat_test, genre_test)\n",
    "\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.38405797  0.47826087  0.44444444]\n",
      "Accuracy: 0.44 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cvs_gbc = cross_val_score(gbc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_gbc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_gbc.mean(), cvs_gbc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
