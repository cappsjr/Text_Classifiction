{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the corpus\n",
    "from nltk.corpus import brown, stopwords\n",
    "\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate the DataFrame with the fileids\n",
    "df['ID'] = brown.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ca01\n",
       "1    ca02\n",
       "2    ca03\n",
       "3    ca04\n",
       "4    ca05\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Populate the DataFrame with the text\n",
    "\n",
    "text = [] # Create an empty list where the text can be stored\n",
    "for each in df['ID']:\n",
    "    txt = brown.words(fileids = [each]) # This returns the text based on the fileid \n",
    "    txt = [i.lower() for i in txt]\n",
    "    txt = ' '.join(txt)\n",
    "    text.append(txt) # Add the text to the list   \n",
    "\n",
    "df['text'] = text # Create a new column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text\n",
       "0  ca01  the fulton county grand jury said friday an in...\n",
       "1  ca02  austin , texas -- committee approval of gov. p...\n",
       "2  ca03  several defendants in the summerdale police bu...\n",
       "3  ca04  oslo the most positive element to emerge from ...\n",
       "4  ca05  east providence should organize its civil defe..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text genre\n",
       "0  ca01  the fulton county grand jury said friday an in...  news\n",
       "1  ca02  austin , texas -- committee approval of gov. p...  news\n",
       "2  ca03  several defendants in the summerdale police bu...  news\n",
       "3  ca04  oslo the most positive element to emerge from ...  news\n",
       "4  ca05  east providence should organize its civil defe...  news"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the DataFrame with the genre of the text\n",
    "\n",
    "categories = []\n",
    "for each in df['ID']:\n",
    "    cat = brown.categories(fileids = [each])\n",
    "    cat = ' '.join(cat)\n",
    "    categories.append(cat)\n",
    "\n",
    "df['genre'] = categories\n",
    "\n",
    "df.head() # Take a look at the DataFrame to see what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'),\n",
    "                            max_df=0.5,\n",
    "                            min_df=0.1,\n",
    "                            lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df.genre\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(true_k)\n",
    "lsa = make_pipeline(svd,Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=15, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9,  3, 14, 10,  7, 14, 14,  3,  8, 12, 12, 12, 12, 12,  4,  4,\n",
       "        4,  3,  6,  4,  4,  4, 10,  3,  3,  3,  3,  4,  4,  8, 12,  4, 10,\n",
       "        9,  7, 14, 12, 12, 12, 14, 14,  3,  3,  7, 14, 10, 14, 10, 14, 14,\n",
       "        8, 10,  1, 14, 10,  1, 10,  3,  9, 14, 14, 14, 14, 14, 14, 14,  1,\n",
       "       14, 14, 14,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1, 10,  1,  1, 10,\n",
       "        6, 14,  3, 11,  8,  8,  8,  8,  8,  8, 11,  8, 11, 11, 11,  2,  8,\n",
       "       11,  8,  8, 10,  2, 14,  1,  4,  3,  2,  5, 12, 12,  6,  6, 13,  2,\n",
       "        2,  2,  2,  6,  2,  2,  2,  1,  1,  9,  5,  9,  3,  3,  9,  3,  3,\n",
       "        3,  3,  5,  3,  3,  1,  6, 11,  9,  2,  1, 11,  1,  6,  4,  2,  1,\n",
       "        3, 14, 11,  6,  6,  6, 11,  6,  2,  6, 14,  6,  9,  2,  2,  6,  4,\n",
       "        9,  4,  9,  9,  3,  2, 13,  8, 12, 11,  3,  8,  6,  1, 11,  6,  7,\n",
       "        9, 11,  6, 14, 14, 13,  2,  1, 14,  6, 11,  7, 11,  1, 11, 13,  1,\n",
       "       11,  6,  1, 11,  5, 14, 11, 11, 11, 11,  1,  6,  6, 11,  5,  1,  4,\n",
       "        1,  1, 14, 10,  6, 14,  1, 10,  4, 11, 11, 11, 10, 11,  0,  6,  1,\n",
       "        6,  1, 14,  6,  0,  8, 11,  9,  6,  6,  0, 11, 14, 11, 10, 11,  6,\n",
       "        4,  9, 11, 11, 11, 14,  1,  1,  6,  3,  3, 14,  7,  7,  7,  7,  7,\n",
       "        7,  3,  5,  7, 10,  7,  2,  7,  7, 14, 14,  3,  3,  7,  3,  7, 14,\n",
       "       10,  3,  9,  3, 14,  5,  5,  5,  5,  5,  5,  5,  5,  5,  1,  2,  5,\n",
       "        2,  5,  5,  5,  5,  5,  5,  5,  5, 14, 11, 11, 11,  5,  9, 11,  9,\n",
       "        1,  1,  5,  1,  5,  5, 14, 14,  9,  1,  3,  3, 14,  7,  7,  5,  7,\n",
       "        9,  9,  9,  3, 11, 11, 11, 11, 13,  6, 11,  6,  5,  3,  2, 11, 11,\n",
       "        1,  1,  1, 11,  1,  5,  5,  5,  5,  5,  3,  5,  5,  2,  5,  7,  5,\n",
       "        0, 13,  0,  8,  0,  8,  0,  1, 13,  8, 13,  0,  0,  0,  0, 13,  0,\n",
       "        0,  0,  0, 13,  4, 13,  0,  0,  0, 13,  0,  0,  0,  0, 13, 13, 13,\n",
       "       13,  0, 10,  0,  0,  0,  0,  0,  0,  4, 13,  0,  0, 13,  4, 13,  0,\n",
       "        0,  0,  0,  6, 11,  0,  1,  0,  0, 13, 13, 13, 13,  0, 13, 13,  0,\n",
       "        0, 13, 13, 13, 13, 13, 13,  0,  0,  0, 13,  0, 13,  0,  0, 13, 13,\n",
       "        0,  0, 13, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,\n",
       "        0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0, 13,  0,  0, 10,  0,  0,\n",
       "        1, 10,  0,  1,  0,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39266299793743681"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819388602370859"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38722669280174105"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16796493654276209"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>adventure</th>\n",
       "      <th>belles_lettres</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>humor</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>mystery</th>\n",
       "      <th>news</th>\n",
       "      <th>religion</th>\n",
       "      <th>reviews</th>\n",
       "      <th>romance</th>\n",
       "      <th>science_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  adventure  belles_lettres  editorial  fiction  government  hobbies  \\\n",
       "k                                                                           \n",
       "0             12               3          0       17           0        0   \n",
       "1              0              13          3        1           0        3   \n",
       "2              0               1          0        0           1        9   \n",
       "3              0               0          1        0           8        9   \n",
       "4              0               3          0        1           0        1   \n",
       "5              0               2          0        0           1        3   \n",
       "6              0              13          0        0           0        3   \n",
       "7              0               1          1        0          12        0   \n",
       "8              0               1          1        3           0        0   \n",
       "9              0               2          1        0           1        3   \n",
       "10             0               4          5        0           2        1   \n",
       "11             0              21          0        0           0        0   \n",
       "12             0               0          0        0           0        2   \n",
       "13            17               2          0        7           0        1   \n",
       "14             0               9         15        0           5        1   \n",
       "\n",
       "genre  humor  learned  lore  mystery  news  religion  reviews  romance  \\\n",
       "k                                                                        \n",
       "0          4        0     0       14     0         0        0       24   \n",
       "1          4        9     5        0     0         0       11        0   \n",
       "2          0        4     6        0     0         1        0        0   \n",
       "3          0        5     3        0     9         0        1        0   \n",
       "4          0        0     3        2     9         0        0        1   \n",
       "5          0       33     0        0     0         0        0        0   \n",
       "6          0        2    11        0     1         0        1        0   \n",
       "7          0        4     1        0     3         0        0        0   \n",
       "8          0        0     2        0     2        10        0        1   \n",
       "9          0        6     6        0     2         0        0        0   \n",
       "10         1        0     0        1     3         0        3        1   \n",
       "11         0       12     7        0     0         6        0        0   \n",
       "12         0        0     1        0     9         0        0        0   \n",
       "13         0        1     1        7     0         0        0        2   \n",
       "14         0        4     2        0     6         0        1        0   \n",
       "\n",
       "genre  science_fiction  \n",
       "k                       \n",
       "0                    3  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    1  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   1  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['k'] = km.labels_\n",
    "\n",
    "pd.crosstab(df['k'], df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: got eyes went thought knew door looked room going told something house face think felt asked woman mother let us\n",
      "\n",
      "Cluster 1: music art love miss us young performance mother century form book though york experience stage american mr sense english often\n",
      "\n",
      "Cluster 2: water surface used feet system small state head shown air area body earth light side pressure ground half size 10\n",
      "\n",
      "Cluster 3: per 000 year industry cost program development system company million 1960 car market service equipment business cent government rate production\n",
      "\n",
      "Cluster 4: mrs mr house president miss car white room home year family club woman police door wife school office children mother\n",
      "\n",
      "Cluster 5: surface used system pressure shown number volume type water systems per information material method study range low small obtained possible\n",
      "\n",
      "Cluster 6: south war north southern john river american company england wrote west english east states 000 century city year united york\n",
      "\n",
      "Cluster 7: state states federal court united law year government secretary department 000 congress public county act shall per program labor general\n",
      "\n",
      "Cluster 8: church god john religious members us faith st city say england sunday love law peace spirit board death heart social\n",
      "\n",
      "Cluster 9: school college students schools children education university student class social child year training members program board family girls president study\n",
      "\n",
      "Cluster 10: mr american president state party miss music city program york brown committee john got war board us car night house\n",
      "\n",
      "Cluster 11: social human experience us society sense religious century political art fact form community history self moral values literature power action\n",
      "\n",
      "Cluster 12: game year season home hit club play run john shot field york four bill week 30 record state got president\n",
      "\n",
      "Cluster 13: eyes door water head got looked feet went car face saw side knew house away hand turned across road street\n",
      "\n",
      "Cluster 14: president united war states government american state nations political military mr national policy economic secretary party administration west peace 000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "\n",
    "text_train, text_test, categories_train, categories_test = train_test_split(\n",
    "    text, categories, test_size=0.25, random_state=42, stratify=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learned            20\n",
       "belles_lettres     19\n",
       "lore               12\n",
       "news               11\n",
       "hobbies             9\n",
       "government          8\n",
       "fiction             7\n",
       "romance             7\n",
       "editorial           7\n",
       "adventure           7\n",
       "mystery             6\n",
       "religion            4\n",
       "reviews             4\n",
       "science_fiction     2\n",
       "humor               2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(categories_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 18959\n",
      "Number of features: 18959\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.tfidfvectorizer to vectorize the data\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf=vectorizer.fit_transform(text_train)\n",
    "print(\"Number of features: %d\" % train_tfidf.get_shape()[1])\n",
    "\n",
    "test_tfidf = vectorizer.transform(text_test)\n",
    "print(\"Number of features: %d\" % test_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit = rfc.fit(train_tfidf, categories_train)\n",
    "predict = rfc.predict(test_tfidf)\n",
    "score = rfc.score(test_tfidf, categories_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text = vectorizer.fit_transform(text)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_rfc = cross_val_score(rfc, vector_text, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.31360947  0.25443787  0.29012346]\n",
      "Accuracy: 0.29 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc.mean(), cross_val_rfc.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are pretty awful.  I am going to analyze the data to see where the models are making mistakes and then adjust the data hopefully make the models more accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned            80\n",
      "belles_lettres     75\n",
      "lore               48\n",
      "news               44\n",
      "hobbies            36\n",
      "government         30\n",
      "fiction            29\n",
      "romance            29\n",
      "adventure          29\n",
      "editorial          27\n",
      "mystery            24\n",
      "religion           17\n",
      "reviews            17\n",
      "humor               9\n",
      "science_fiction     6\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine how many titles are in each genre\n",
    "\n",
    "print(df['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned           80\n",
      "belles_lettres    75\n",
      "lore              48\n",
      "news              44\n",
      "hobbies           36\n",
      "government        30\n",
      "fiction           29\n",
      "romance           29\n",
      "adventure         29\n",
      "editorial         27\n",
      "mystery           24\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We will drop the bottom four genres because there are not enough titles to adequately\n",
    "# train the models to recognize them\n",
    "\n",
    "df1 = df # create a new DataFrame\n",
    "\n",
    "\n",
    "drop_list = ['science_fiction', 'humor', 'reviews', 'religion']\n",
    "for each in drop_list:\n",
    "    df1 = df1[df1.genre != each]\n",
    "\n",
    "print(df1['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for the text and genre in the new DataFrame\n",
    "text1 = df1['text']\n",
    "categories1 = df1['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train1, text_test1, categories_train1, categories_test1 = train_test_split(\n",
    "    text1, categories1, test_size=0.25, random_state=42, stratify=categories1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17616\n",
      "Number of features: 17616\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf1 = vectorizer.fit_transform(text_train1)\n",
    "print(\"Number of features: %d\" % train_tfidf1.get_shape()[1])\n",
    "\n",
    "test_tfidf1 = vectorizer.transform(text_test1)\n",
    "print(\"Number of features: %d\" % test_tfidf1.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit1 = rfc.fit(train_tfidf1, categories_train1)\n",
    "predict1 = rfc.predict(test_tfidf1)\n",
    "score1 = rfc.score(test_tfidf1, categories_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.40707964601769914\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text1 = vectorizer.fit_transform(text1)\n",
    "\n",
    "cross_val_rfc1 = cross_val_score(rfc, vector_text1, categories1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.34210526  0.30263158  0.27891156]\n",
      "Accuracy: 0.31 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc1.mean(), cross_val_rfc1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the model has gotten fractionally better, but it is still pretty awful.  After further examination of the clustered data above, it appears that adventure, fiction, mystery, and romance are frequently clustered together.  We will combine those categories under the genre 'fiction' and rerun the model and hope for increased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction           111\n",
      "learned            80\n",
      "belles_lettres     75\n",
      "lore               48\n",
      "news               44\n",
      "hobbies            36\n",
      "government         30\n",
      "editorial          27\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame\n",
    "\n",
    "df2 = df1\n",
    "\n",
    "# Rename all adventure, mystery, and romance titles\n",
    "replace_list = ['adventure', 'mystery', 'romance']\n",
    "for each in replace_list:\n",
    "    df2 = df2.replace(each, 'fiction')\n",
    "\n",
    "print(df2['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables for the text and genre in the new DataFrame\n",
    "text2 = df2['text']\n",
    "categories2 = df2['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "text_train2, text_test2, categories_train2, categories_test2 = train_test_split(\n",
    "    text2, categories2, test_size=0.25, random_state=42, stratify=categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf2 = vectorizer.fit_transform(text_train2)\n",
    "print(\"Number of features: %d\" % train_tfidf2.get_shape()[1])\n",
    "\n",
    "test_tfidf2 = vectorizer.transform(text_test2)\n",
    "print(\"Number of features: %d\" % test_tfidf2.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "fit2 = rfc.fit(train_tfidf2, categories_train2)\n",
    "predict2 = rfc.predict(test_tfidf2)\n",
    "score2 = rfc.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.48672566371681414\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text2 = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_rfc2 = cross_val_score(rfc, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.53642384  0.43046358  0.4966443 ]\n",
      "Accuracy: 0.49 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc2.mean(), cross_val_rfc2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining adventure, fiction, mystery, and romance resulted in greatly increased model, however the model is still under fifty percent accurate.  More improvements need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try adding a stemmer and tokenizer to the vectorizer.\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    # strip out punctuation and make lowercase\n",
    "    tokens = [token.lower().strip(string.punctuation)\n",
    "             for token in tokens if token.isalnum()]\n",
    "    \n",
    "    # now stem the tokens\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the tokenize_and_stem function to the vectorizer\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True, #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                             tokenizer = tokenize_and_stem\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "train_tfidf3 = vectorizer2.fit_transform(text_train2)\n",
    "print(\"Number of features: %d\" % train_tfidf2.get_shape()[1])\n",
    "\n",
    "test_tfidf3 = vectorizer2.transform(text_test2)\n",
    "print(\"Number of features: %d\" % test_tfidf2.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a supervised model on the vectorized data\n",
    "\n",
    "fit3 = rfc.fit(train_tfidf3, categories_train2)\n",
    "predict3 = rfc.predict(test_tfidf3)\n",
    "score3 = rfc.score(test_tfidf3, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier Score: {}'.format(score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text3 = vectorizer2.fit_transform(text2)\n",
    "\n",
    "cross_val_rfc3 = cross_val_score(rfc, vector_text3, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.53642384  0.40397351  0.48322148]\n",
      "Accuracy: 0.47 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_rfc3))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc3.mean(), cross_val_rfc3.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the tokenize_and_stem function to the vectorizer actually made the model worse.  Looks like I need to find another solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try different supervised learning models and see if we can find a more accurate model\n",
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a support vector machine classifier\n",
    "\n",
    "svc = SVC(kernel = 'linear')\n",
    "\n",
    "fit_svc = svc.fit(train_tfidf2, categories_train2)\n",
    "predict_svc = svc.predict(test_tfidf2)\n",
    "score_svc = svc.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Score: 0.6371681415929203\n"
     ]
    }
   ],
   "source": [
    "print('Support Vector Classifier Score: {}'.format(score_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_svc = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_svc = cross_val_score(svc, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.62913907  0.53642384  0.55704698]\n",
      "Accuracy: 0.57 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_svc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_svc.mean(), cross_val_svc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit_lr = lr.fit(train_tfidf2, categories_train2)\n",
    "predict_lr = lr.predict(test_tfidf2)\n",
    "score_lr = lr.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Score: {}'.format(score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_lr = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_lr = cross_val_score(lr, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.52980132  0.42384106  0.46308725]\n",
      "Accuracy: 0.47 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_lr))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_lr.mean(), cross_val_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a K Nearest Neighbors Classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "fit_knn = knn.fit(train_tfidf2, categories_train2)\n",
    "predict_knn = knn.predict(test_tfidf2)\n",
    "score_knn = knn.score(test_tfidf2, categories_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.6460176991150443\n"
     ]
    }
   ],
   "source": [
    "print('KNN Classifier Score: {}'.format(score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate\n",
    "\n",
    "vector_text_knn = vectorizer.fit_transform(text2)\n",
    "\n",
    "cross_val_knn = cross_val_score(knn, vector_text2, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.60927152  0.52980132  0.52348993]\n",
      "Accuracy: 0.55 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validated Scores: {}'.format(cross_val_knn))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_knn.mean(), cross_val_knn.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supervised model that outputted the best results using the vectorized data was the KNN Classifier with a score of 0.646 and a cross-validated score of 0.55 (+/- 0.08).  However, this is still a very poorly performing model.  In order to try to continue to improve the performance of the models, I am going to add more features using the bag-of-words method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20\n",
      "Number of features: 20\n"
     ]
    }
   ],
   "source": [
    "# Try using a bag-of-words vectorizer--CountVectorizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(stop_words = 'english',\n",
    "                           max_df = 0.5,\n",
    "                           min_df = 2,\n",
    "                           max_features = 20)\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_countvec = count_vec.fit_transform(text_train2)\n",
    "print(\"Number of features: %d\" % train_countvec.get_shape()[1])\n",
    "\n",
    "test_countvec = count_vec.transform(text_test2)\n",
    "print(\"Number of features: %d\" % test_countvec.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the fulton county grand jury said friday an in...\n",
       "1    austin , texas -- committee approval of gov. p...\n",
       "2    several defendants in the summerdale police bu...\n",
       "3    oslo the most positive element to emerge from ...\n",
       "4    east providence should organize its civil defe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "several defendants in the summerdale police burglary trial made statements indicating their guilt at the time of their arrest , judge james b. parsons was told in criminal court yesterday . the disclosure by charles bellows , chief defense counsel , startled observers and was viewed as the prelude to a quarrel between the six attorneys representing the eight former policemen now on trial . bellows made the disclosure when he asked judge parsons to grant his client , alan clements , 30 , a separate trial . bellows made the request while the all-woman jury was out of the courtroom . fears prejudicial aspects `` the statements may be highly prejudicial to my client '' , bellows told the court . `` some of the defendants strongly indicated they knew they were receiving stolen property . it is impossible to get a fair trial when some of the defendants made statements involving themselves and others '' . judge parsons leaned over the bench and inquired , `` you mean some of the defendants made statements admitting this '' ? ? `` yes , your honor '' , replied bellows . `` what this amounts to , if true , is that there will be a free-for-all fight in this case . there is a conflict among the defendants '' . washington , july 24 -- president kennedy today pushed aside other white house business to devote all his time and attention to working on the berlin crisis address he will deliver tomorrow night to the american people over nationwide television and radio . the president spent much of the week-end at his summer home on cape cod writing the first drafts of portions of the address with the help of white house aids in washington with whom he talked by telephone . shortly after the chief executive returned to washington in midmorning from hyannis port , mass. , a white house spokesman said the address text still had `` quite a way to go '' toward completion . decisions are made asked to elaborate , pierre salinger , white house press secretary , replied , `` i would say it's got to go thru several more drafts '' . salinger said the work president kennedy , advisers , and members of his staff were doing on the address involved composition and wording , rather than last minute decisions on administration plans to meet the latest berlin crisis precipitated by russia's demands and proposals for the city . the last 10 cases in the investigation of the nov. 8 election were dismissed yesterday by acting judge john m. karns , who charged that the prosecution obtained evidence `` by unfair and fundamentally illegal means '' . karns said that the cases involved a matter `` of even greater significance than the guilt or innocence '' of the 50 persons . he said evidence was obtained `` in violation of the legal rights of citizens '' . karns' ruling pertained to eight of the 10 cases . in the two other cases he ruled that the state had been `` unable to make a case '' . contempt proceedings originally had been brought against 677 persons in 133 precincts by morris j. wexler , special prosecutor . issue jury subpoenas wexler admitted in earlier court hearings that he issued grand jury subpenas to about 200 persons involved in the election investigation , questioned the individuals in the criminal courts building , but did not take them before the grand jury . mayer goldberg , attorney for election judges in the 58th precinct of the 23d ward , argued this procedure constituted intimidation . wexler has denied repeatedly that coercion was used in questioning . karns said it was a `` wrongful act '' for wexler to take statements `` privately and outside of the grand jury room '' . he said this constituted a `` very serious misuse '' of the criminal court processes . `` actually , the abuse of the process may have constituted a contempt of the criminal court of cook county , altho vindication of the authority of that court is not the function of this court '' , said karns , who is a city judge in east st. louis sitting in cook county court . faced seven cases karns had been scheduled this week to hear seven cases involving 35 persons . wexler had charged the precinct judges in these cases with `` complementary '' miscount of the vote , in which votes would be taken from one candidate and given to another . the cases involved judges in the 33d , 24th , and 42d precincts of the 31st ward , the 21st and 28th precincts of the 29th ward , the 18th precinct of the 4th ward , and the 9th precinct of the 23d ward . the case of the judges in the 58th precinct of the 23d ward had been heard previously and taken under advisement by karns . two other cases also were under advisement . claims precedent lacking after reading his statement discharging the 23d ward case , karns told wexler that if the seven cases scheduled for trial also involved persons who had been subpenaed , he would dismiss them . washington , feb. 9 -- president kennedy today proposed a mammoth new medical care program whereby social security taxes on 70 million american workers would be raised to pay the hospital and some other medical bills of 14.2 million americans over 65 who are covered by social security or railroad retirement programs . the president , in a special message to congress , tied in with his aged care plan requests for large federal grants to finance medical and dental scholarships , build 20 new medical and 20 new dental schools , and expand child health care and general medical research . the aged care plan , similar to one the president sponsored last year as a senator , a fight on capitol hill . it was defeated in congress last year . cost up to $37 a year it would be financed by boosting the social security payroll tax by as much as $37 a year for each of the workers now paying such taxes . the social security payroll tax is now 6 per cent -- 3 per cent on each worker and employer -- on the first $4,800 of pay per year . the kennedy plan alone would boost the base to $5,000 a year and the payroll tax to 6.5 per cent -- 3.25 per cent each . similar payroll tax boosts would be imposed on those under the railroad retirement system . the payroll tax would actually rise to 7.5 per cent starting jan. 1 , 1963 , if the plan is approved , because the levy is already scheduled to go up by 1 per cent on that date to pay for other social security costs . outlays would increase officials estimated the annual tax boost for the medical plan would amount to 1.5 billion dollars and that medical benefits paid out would run 1 billion or more in the first year , 1963 . both figures would go higher in later years . other parts of the kennedy health plan would entail federal grants of 750 million to 1 billion dollars over the next 10 years . these would be paid for out of general , not payroll , taxes . nursing home care the aged care plan carries these benefits for persons over 65 who are under the social security and railroad retirement systems : 1 full payment of hospital bills for stays up to 90 days for each illness , except that the patient would pay $10 a day of the cost for the first nine days . 2 full payment of nursing home bills for up to 180 days following discharge from a hospital . a patient could receive up to 300 days paid-for nursing home care under a `` unit formula '' allowing more of such care for those who use none or only part of the hospital-care credit . 3 hospital outpatient clinic diagnostic service for all costs in excess of $20 a patient . 4 community visiting nurse services at home for up to 240 days an illness . the president noted that congress last year passed a law providing grants to states to help pay medical bills of the needy aged . calls proposal modest he said his plan is designed to `` meet the needs of those millions who have no wish to receive care at the taxpayers' expense , but who are nevertheless staggered by the drain on their savings -- or those of their children -- caused by an extended hospital stay '' . `` this is a very modest proposal cut to meet absolutely essential needs '' , he said , `` and with sufficient ' deductible ' requirements to discourage any malingering or unnecessary overcrowding of our hospitals . `` this is not a program of socialized medicine . it is a program of prepayment of health costs with absolute freedom of choice guaranteed . every person will choose his own doctor and hospital '' . wouldn't pay doctors the plan does not cover doctor bills . they would still be paid by the patient . apart from the aged care plan the president's most ambitious and costly proposals were for federal scholarships , and grants to build or enlarge medical and dental schools . the president said the nation's 92 medical and 47 dental schools cannot now handle the student load needed to meet the rising need for health care . moreover , he said , many qualified young people are not going into medicine and dentistry because they can't afford the schooling costs . contributions to schools the scholarship plan would provide federal contributions to each medical and dental school equal to $1,500 a year for one-fourth of the first year students . the schools could use the money to pay 4-year scholarships , based on need , of up to $2,000 a year per student . in addition , the government would pay a $1,000 `` cost of education '' grant to the schools for each $1,500 in scholarship grants . officials estimated the combined programs would cost 5.1 million dollars the first year and would go up to 21 millions by 1966 . the president recommended federal `` matching grants '' totaling 700 million dollars in 10 years for constructing new medical and dental schools or enlarging the capacity of existing ones . more for nursing homes in the area of `` community health services '' , the president called for doubling the present 10 million dollar a year federal grants for nursing home construction . he asked for another 10 million dollar `` initial '' appropriation for `` stimulatory grants '' to states to improve nursing homes . he further proposed grants of an unspecified sum for experimental hospitals . in the child health field , the president said he will recommend later an increase in funds for programs under the children's bureau . he also asked congress to approve establishment of a national child health institute . asks research funds the president said he will ask congress to increase grants to states for vocational rehabilitation . he did not say by how much . for medical research he asked a 20 million dollar a year increase , from 30 to 50 millions , in matching grants for building research facilities . the president said he will also propose increasing , by an unspecified amount , the 540 million dollars in the 1961-62 budget for direct government research in medicine . the president said his proposals combine the `` indispensable elements in a sound health program -- people , knowledge , services , facilities , and the means to pay for them '' . reaction as expected congressional reaction to the message was along expected lines . legislators who last year opposed placing aged-care under the social security system criticized the president's plan . those who backed a similar plan last year hailed the message . senate republican leader dirksen ( ill. ) and house republican leader charles halleck ( ind. ) said the message did not persuade them to change their opposition to compulsory medical insurance . halleck said the voluntary care plan enacted last year should be given a fair trial first . house speaker sam rayburn ( d. , tex. ) called the kennedy program `` a mighty fine thing '' , but made no prediction on its fate in the house . washington , feb. 9 -- acting hastily under white house pressure , the senate tonight confirmed robert c. weaver as the nation's federal housing chief . only 11 senators were on the floor and there was no record vote . a number of scattered `` ayes '' and `` noes '' was heard . customary senate rules were ignored in order to speed approval of the negro leader as administrator of the housing and home finance agency . in the last eight years , all presidential appointments , including those of cabinet rank , have been denied immediate action because of a senate rule requiring at least a 24 hour delay after they are reported to the floor . enforce by demand the rule was enforced by demand of sen. wayne morse ( d. , ore. ) in connection with president eisenhower's cabinet selections in 1953 and president kennedy's in 1961 ."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rar = nlp(text2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 10 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(11)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'say',\n",
       " 'jury',\n",
       " 'have',\n",
       " 'county',\n",
       " 'fulton',\n",
       " 'election',\n",
       " 'department',\n",
       " 'state',\n",
       " 'fund',\n",
       " 'city',\n",
       " 'vote',\n",
       " 'bond',\n",
       " 'resolution',\n",
       " 'mayor',\n",
       " 'georgia',\n",
       " 'highway',\n",
       " 'atlanta',\n",
       " 'william',\n",
       " 'court']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rar = nlp(df2['text'][0])\n",
    "bag_of_words(rar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the fulton county grand jury said friday an investigation of atlanta's recent primary election produced `` no evidence '' that any irregularities took place . the jury further said in term-end presentments that the city executive committee , which had over-all charge of the election , `` deserves the praise and thanks of the city of atlanta '' for the manner in which the election was conducted . the september-october term jury had been charged by fulton superior court judge durwood pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by mayor-nominate ivan allen jr. . `` only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' . the jury said it did find that many of georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' . it recommended that fulton legislators act `` to have these laws studied and revised to the end of modernizing and improving them '' . the grand jury commented on a number of other topics , among them the atlanta and fulton county purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best interest of both governments '' . merger proposed however , the jury said it believes `` these two offices should be combined to achieve greater efficiency and reduce the cost of administration '' . the city purchasing department , the jury said , `` is lacking in experienced clerical personnel as a result of city personnel policies '' . it urged that the city `` take steps to remedy '' this problem . implementation of georgia's automobile title law was also recommended by the outgoing jury . it urged that the next legislature `` provide enabling funds and re-set the effective date so that an orderly implementation of the law may be effected '' . the grand jury took a swipe at the state welfare department's handling of federal funds granted for child welfare services in foster homes . `` this is one of the major items in the fulton county general assistance program '' , the jury said , but the state welfare department `` has seen fit to distribute these funds through the welfare departments of all the counties in the state with the exception of fulton county , which receives none of this money . the jurors said they realize `` a proportionate distribution of these funds might disable this program in our less populous counties '' . nevertheless , `` we feel that in the future fulton county should receive some portion of these available funds '' , the jurors said . `` failure to do this will continue to place a disproportionate burden '' on fulton taxpayers . the jury also commented on the fulton ordinary's court which has been under fire for its practices in the appointment of appraisers , guardians and administrators and the awarding of fees and compensation . wards protected the jury said it found the court `` has incorporated into its operating procedures the recommendations '' of two previous grand juries , the atlanta bar association and an interim citizens committee . `` these actions should serve to protect in fact and in effect the court's wards from undue costs and its appointed and elected servants from unmeritorious criticisms '' , the jury said . regarding atlanta's new multi-million-dollar airport , the jury recommended `` that when the new management takes charge jan. 1 the airport be operated in a manner that will eliminate political influences '' . the jury did not elaborate , but it added that `` there should be periodic surveillance of the pricing practices of the concessionaires for the purpose of keeping the prices reasonable '' . ask jail deputies on other matters , the jury recommended that : ( 1 ) four additional deputies be employed at the fulton county jail and `` a doctor , medical intern or extern be employed for night and weekend duty at the jail '' . ( 2 ) fulton legislators `` work with city officials to pass enabling legislation that will permit the establishment of a fair and equitable '' pension plan for city employes . the jury praised the administration and operation of the atlanta police department , the fulton tax commissioner's office , the bellwood and alpharetta prison farms , grady hospital and the fulton health department . mayor william b. hartsfield filed suit for divorce from his wife , pearl williams hartsfield , in fulton superior court friday . his petition charged mental cruelty . the couple was married aug. 2 , 1913 . they have a son , william berry jr. , and a daughter , mrs. j. m. cheshire of griffin . attorneys for the mayor said that an amicable property settlement has been agreed upon . the petition listed the mayor's occupation as `` attorney '' and his age as 71 . it listed his wife's age as 74 and place of birth as opelika , ala. . the petition said that the couple has not lived together as man and wife for more than a year . the hartsfield home is at 637 e. pelham rd. aj . henry l. bowden was listed on the petition as the mayor's attorney . hartsfield has been mayor of atlanta , with exception of one brief interlude , since 1937 . his political career goes back to his election to city council in 1923 . the mayor's present term of office expires jan. 1 . he will be succeeded by ivan allen jr. , who became a candidate in the sept. 13 primary after mayor hartsfield announced that he would not run for reelection . georgia republicans are getting strong encouragement to enter a candidate in the 1962 governor's race , a top official said wednesday . robert snodgrass , state gop chairman , said a meeting held tuesday night in blue ridge brought enthusiastic responses from the audience . state party chairman james w. dorsey added that enthusiasm was picking up for a state rally to be held sept. 8 in savannah at which newly elected texas sen. john tower will be the featured speaker . in the blue ridge meeting , the audience was warned that entering a candidate for governor would force it to take petitions out into voting precincts to obtain the signatures of registered voters . despite the warning , there was a unanimous vote to enter a candidate , according to republicans who attended . when the crowd was asked whether it wanted to wait one more term to make the race , it voted no -- and there were no dissents . the largest hurdle the republicans would have to face is a state law which says that before making a first race , one of two alternative courses must be taken : 1 five per cent of the voters in each county must sign petitions requesting that the republicans be allowed to place names of candidates on the general election ballot , or 2 the republicans must hold a primary under the county unit system -- a system which the party opposes in its platform . sam caldwell , state highway department public relations director , resigned tuesday to work for lt. gov. garland byrd's campaign . caldwell's resignation had been expected for some time . he will be succeeded by rob ledford of gainesville , who has been an assistant more than three years . when the gubernatorial campaign starts , caldwell is expected to become a campaign coordinator for byrd . the georgia legislature will wind up its 1961 session monday and head for home -- where some of the highway bond money it approved will follow shortly . before adjournment monday afternoon , the senate is expected to approve a study of the number of legislators allotted to rural and urban areas to determine what adjustments should be made . gov. vandiver is expected to make the traditional visit to both chambers as they work toward adjournment . vandiver likely will mention the $100 million highway bond issue approved earlier in the session as his first priority item . construction bonds meanwhile , it was learned the state highway department is very near being ready to issue the first $30 million worth of highway reconstruction bonds . the bond issue will go to the state courts for a friendly test suit to test the validity of the act , and then the sales will begin and contracts let for repair work on some of georgia's most heavily traveled highways . a highway department source said there also is a plan there to issue some $3 million to $4 million worth of rural roads authority bonds for rural road construction work . a revolving fund the department apparently intends to make the rural roads authority a revolving fund under which new bonds would be issued every time a portion of the old ones are paid off by tax authorities . vandiver opened his race for governor in 1958 with a battle in the legislature against the issuance of $50 million worth of additional rural roads bonds proposed by then gov. marvin griffin . the highway department source told the constitution , however , that vandiver has not been consulted yet about the plans to issue the new rural roads bonds . schley county rep. b. d. pelham will offer a resolution monday in the house to rescind the body's action of friday in voting itself a $10 per day increase in expense allowances . pelham said sunday night there was research being done on whether the `` quickie '' vote on the increase can be repealed outright or whether notice would have to first be given that reconsideration of the action would be sought . while emphasizing that technical details were not fully worked out , pelham said his resolution would seek to set aside the privilege resolution which the house voted through 87-31 . a similar resolution passed in the senate by a vote of 29-5 . as of sunday night , there was no word of a resolution being offered there to rescind the action . pelham pointed out that georgia voters last november rejected a constitutional amendment to allow legislators to vote on pay raises for future legislature sessions . a veteran jackson county legislator will ask the georgia house monday to back federal aid to education , something it has consistently opposed in the past . rep. mac barber of commerce is asking the house in a privilege resolution to `` endorse increased federal support for public education , provided that such funds be received and expended '' as state funds . barber , who is in his 13th year as a legislator , said there `` are some members of our congressional delegation in washington who would like to see it ( the resolution ) passed '' . but he added that none of georgia's congressmen specifically asked him to offer the resolution . the resolution , which barber tossed into the house hopper friday , will be formally read monday . it says that `` in the event congress does provide this increase in federal funds '' , the state board of education should be directed to `` give priority '' to teacher pay raises . colquitt -- after a long , hot controversy , miller county has a new school superintendent , elected , as a policeman put it , in the `` coolest election i ever saw in this county '' . the new school superintendent is harry davis , a veteran agriculture teacher , who defeated felix bush , a school principal and chairman of the miller county democratic executive committee . davis received 1,119 votes in saturday's election , and bush got 402 . ordinary carey williams , armed with a pistol , stood by at the polls to insure order . `` this was the coolest , calmest election i ever saw '' , colquitt policeman tom williams said . `` being at the polls was just like being at church . i didn't smell a drop of liquor , and we didn't have a bit of trouble '' . the campaign leading to the election was not so quiet , however . it was marked by controversy , anonymous midnight phone calls and veiled threats of violence . the former county school superintendent , george p. callan , shot himself to death march 18 , four days after he resigned his post in a dispute with the county school board . during the election campaign , both candidates , davis and bush , reportedly received anonymous telephone calls . ordinary williams said he , too , was subjected to anonymous calls soon after he scheduled the election . many local citizens feared that there would be irregularities at the polls , and williams got himself a permit to carry a gun and promised an orderly election . sheriff felix tabb said the ordinary apparently made good his promise . `` everything went real smooth '' , the sheriff said . `` there wasn't a bit of trouble '' .\""
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rar_list = []\n",
    "for each in df2['text']:\n",
    "    rar_list.append(each)\n",
    "    \n",
    "rar_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got int)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-456a2eec59f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrar_list1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrar_list1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'An'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got int)"
     ]
    }
   ],
   "source": [
    "rar_list1 = []\n",
    "for each in rar_list:\n",
    "    t = nlp(each)\n",
    "    rar_list1.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = []\n",
    "for each in rar_list1:\n",
    "    w = bag_of_words(each)\n",
    "    for words in w:\n",
    "        common_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3157"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = set(common_words)\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fiction           111\n",
       "learned            80\n",
       "belles_lettres     75\n",
       "lore               48\n",
       "news               44\n",
       "hobbies            36\n",
       "government         30\n",
       "editorial          27\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames that isolate texts be genre\n",
    "\n",
    "# fiction\n",
    "df_fic = df2\n",
    "df_fic = df_fic[df_fic.genre == 'fiction' ]\n",
    "\n",
    "# learned\n",
    "df_learn = df2\n",
    "df_learn = df_learn[df_learn.genre == 'learned']\n",
    "\n",
    "# belles_lettres\n",
    "df_bell = df2\n",
    "df_bell = df_bell[df_bell.genre == 'belles_lettres']\n",
    "\n",
    "# lore\n",
    "df_lore = df2\n",
    "df_lore = df_lore[df_lore.genre == 'lore']\n",
    "\n",
    "# news\n",
    "df_news = df2\n",
    "df_news = df_news[df_news.genre == 'news']\n",
    "\n",
    "# hobbies\n",
    "df_hob = df2\n",
    "df_hob = df_hob[df_hob.genre == 'hobbies']\n",
    "\n",
    "# government\n",
    "df_gov = df2\n",
    "df_gov = df_gov[df_gov.genre == 'government']\n",
    "\n",
    "# editorial\n",
    "df_ed = df2\n",
    "df_ed = df_ed[df_ed.genre == 'editorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Remove the `` from the text because it pops up as one of the most common words for each\n",
    "# genre.\n",
    "# Combine all the texts from each genre. Parse each newly created text.\n",
    "\n",
    "df_fic['text'] = df_fic['text'].str.replace('``', '')\n",
    "fiction = ''.join(df_fic['text'].tolist())\n",
    "fiction = nlp(fiction)\n",
    "\n",
    "df_learn['text'] = df_learn['text'].str.replace('``', '')\n",
    "learned = ''.join(df_learn['text'].tolist())\n",
    "learned = nlp(learned)\n",
    "\n",
    "df_bell['text'] = df_bell['text'].str.replace('``', '')\n",
    "belles = ''.join(df_bell['text'].tolist())\n",
    "belles = nlp(belles)\n",
    "\n",
    "#lore\n",
    "df_lore['text'] = df_lore['text'].str.replace('``', '')\n",
    "lore = ''.join(df_lore['text'].tolist())\n",
    "lore = nlp(lore)\n",
    "\n",
    "# news\n",
    "df_news['text'] = df_news['text'].str.replace('``', '')\n",
    "news = ''.join(df_news['text'].tolist())\n",
    "news = nlp(news)\n",
    "\n",
    "#hob\n",
    "df_hob['text'] = df_hob['text'].str.replace('``', '')\n",
    "hobbies = ''.join(df_hob['text'].tolist())\n",
    "hobbies = nlp(hobbies)\n",
    "\n",
    "df_gov['text'] = df_gov['text'].str.replace('``', '')\n",
    "government= ''.join(df_gov['text'].tolist())\n",
    "government = nlp(government)\n",
    "\n",
    "df_ed['text'] = df_ed['text'].str.replace('``', '')\n",
    "editorial = ''.join(df_ed['text'].tolist())\n",
    "editorial = nlp(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the parsed texts through the bag-of-words function to find the most common words\n",
    "# for each genre.\n",
    "\n",
    "fiction_bow = bag_of_words(fiction)\n",
    "learned_bow = bag_of_words(learned)\n",
    "belles_bow = bag_of_words(belles)\n",
    "lore_bow = bag_of_words(lore)\n",
    "news_bow = bag_of_words(news)\n",
    "hobbies_bow = bag_of_words(hobbies)\n",
    "government_bow = bag_of_words(government)\n",
    "editorial_bow = bag_of_words(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the bags to create a set of unique words\n",
    "\n",
    "common_words = set(fiction_bow + learned_bow + belles_bow + lore_bow + news_bow + hobbies_bow + government_bow + editorial_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Parse each of the texts individually\n",
    "\n",
    "# Fiction\n",
    "rar_list = []\n",
    "for each in df_fic['text']:\n",
    "    rar_list.append(each)\n",
    "rar_list1 = []\n",
    "for each in rar_list:\n",
    "    t = nlp(each)\n",
    "    rar_list1.append(t)\n",
    "df_fic['text'] = rar_list1\n",
    "\n",
    "# Learned\n",
    "star_list = []\n",
    "for each in df_learn['text']:\n",
    "    star_list.append(each)\n",
    "sun_list = []\n",
    "for each in star_list:\n",
    "    t = nlp(each)\n",
    "    sun_list.append(t)\n",
    "df_learn['text'] = sun_list\n",
    "\n",
    "# Belles Lettres\n",
    "star_list1 = []\n",
    "for each in df_bell['text']:\n",
    "    star_list1.append(each)\n",
    "sun_list1 = []\n",
    "for each in star_list1:\n",
    "    t = nlp(each)\n",
    "    sun_list1.append(t)\n",
    "df_bell['text'] = sun_list1\n",
    "\n",
    "# Lore\n",
    "star_list2 = []\n",
    "for each in df_lore['text']:\n",
    "    star_list2.append(each)\n",
    "sun_list2 = []\n",
    "for each in star_list2:\n",
    "    t = nlp(each)\n",
    "    sun_list2.append(t)\n",
    "df_lore['text'] = sun_list2\n",
    "\n",
    "# News\n",
    "star_list3 = []\n",
    "for each in df_news['text']:\n",
    "    star_list3.append(each)\n",
    "sun_list3 = []\n",
    "for each in star_list3:\n",
    "    t = nlp(each)\n",
    "    sun_list3.append(t)\n",
    "df_news['text'] = sun_list3\n",
    "\n",
    "# Hobbies\n",
    "star_list4 = []\n",
    "for each in df_hob['text']:\n",
    "    star_list4.append(each)\n",
    "sun_list4 = []\n",
    "for each in star_list4:\n",
    "    t = nlp(each)\n",
    "    sun_list4.append(t)\n",
    "df_hob['text'] = sun_list4\n",
    "\n",
    "# Government\n",
    "star_list5 = []\n",
    "for each in df_gov['text']:\n",
    "    star_list5.append(each)\n",
    "sun_list5 = []\n",
    "for each in star_list5:\n",
    "    t = nlp(each)\n",
    "    sun_list5.append(t)\n",
    "df_gov['text'] = sun_list5\n",
    "\n",
    "# Editorials\n",
    "star_list6 = []\n",
    "for each in df_ed['text']:\n",
    "    star_list6.append(each)\n",
    "sun_list6 = []\n",
    "for each in star_list6:\n",
    "    t = nlp(each)\n",
    "    sun_list6.append(t)\n",
    "df_ed['text'] = sun_list6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_fic, df_learn, df_bell, df_lore, df_news, df_hob, df_gov, df_ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>ck01</td>\n",
       "      <td>(thirty, -, three, scotty, did, not, go, back,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>ck02</td>\n",
       "      <td>(where, their, sharp, edges, seemed, restless,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>ck03</td>\n",
       "      <td>(mickie, sat, over, his, second, whisky, -, on...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>ck04</td>\n",
       "      <td>(the, bishop, looked, at, him, coldly, and, sa...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>ck05</td>\n",
       "      <td>(payne, dismounted, in, madison, place, and, h...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>ck06</td>\n",
       "      <td>(with, a, sneer, ,, the, man, spread, his, leg...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>ck07</td>\n",
       "      <td>(if, the, crummy, bastard, could, write, !, !,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>ck08</td>\n",
       "      <td>(rousseau, is, so, persuasive, that, voltaire,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>ck09</td>\n",
       "      <td>(it, was, the, first, time, any, of, us, had, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>ck10</td>\n",
       "      <td>(that, summer, the, gambling, houses, were, cl...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>ck11</td>\n",
       "      <td>(standing, in, the, shelter, of, the, tent, --...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ck12</td>\n",
       "      <td>(she, was, a, child, too, much, a, part, of, h...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>ck13</td>\n",
       "      <td>(in, the, dim, underwater, light, they, dresse...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ck14</td>\n",
       "      <td>(he, brought, with, him, a, mixture, of, myrrh...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>ck15</td>\n",
       "      <td>(beth, was, very, still, and, her, breath, cam...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>ck16</td>\n",
       "      <td>(the, red, glow, from, the, cove, had, died, o...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>ck17</td>\n",
       "      <td>(burly, leathered, men, and, wrinkled, women, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>ck18</td>\n",
       "      <td>(she, was, getting, real, dramatic, ., i, 'd, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>ck19</td>\n",
       "      <td>(there, was, one, fact, which, rector, could, ...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>ck20</td>\n",
       "      <td>(she, concluded, by, asking, him, to, name, an...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               text    genre   k\n",
       "374  ck01  (thirty, -, three, scotty, did, not, go, back,...  fiction   0\n",
       "375  ck02  (where, their, sharp, edges, seemed, restless,...  fiction  13\n",
       "376  ck03  (mickie, sat, over, his, second, whisky, -, on...  fiction   0\n",
       "377  ck04  (the, bishop, looked, at, him, coldly, and, sa...  fiction   8\n",
       "378  ck05  (payne, dismounted, in, madison, place, and, h...  fiction   0\n",
       "379  ck06  (with, a, sneer, ,, the, man, spread, his, leg...  fiction   8\n",
       "380  ck07  (if, the, crummy, bastard, could, write, !, !,...  fiction   0\n",
       "381  ck08  (rousseau, is, so, persuasive, that, voltaire,...  fiction   1\n",
       "382  ck09  (it, was, the, first, time, any, of, us, had, ...  fiction  13\n",
       "383  ck10  (that, summer, the, gambling, houses, were, cl...  fiction   8\n",
       "384  ck11  (standing, in, the, shelter, of, the, tent, --...  fiction  13\n",
       "385  ck12  (she, was, a, child, too, much, a, part, of, h...  fiction   0\n",
       "386  ck13  (in, the, dim, underwater, light, they, dresse...  fiction   0\n",
       "387  ck14  (he, brought, with, him, a, mixture, of, myrrh...  fiction   0\n",
       "388  ck15  (beth, was, very, still, and, her, breath, cam...  fiction   0\n",
       "389  ck16  (the, red, glow, from, the, cove, had, died, o...  fiction  13\n",
       "390  ck17  (burly, leathered, men, and, wrinkled, women, ...  fiction   0\n",
       "391  ck18  (she, was, getting, real, dramatic, ., i, 'd, ...  fiction   0\n",
       "392  ck19  (there, was, one, fact, which, rector, could, ...  fiction   0\n",
       "393  ck20  (she, concluded, by, asking, him, to, name, an...  fiction   0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df_bow = pd.DataFrame(columns=common_words)\n",
    "    df_bow['text'] = df_new['text']\n",
    "    df_bow.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, corp in enumerate(df_bow['text']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in corp\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df_bow.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    df_bow.loc[i, word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mr</th>\n",
       "      <th>not</th>\n",
       "      <th>world</th>\n",
       "      <th>1</th>\n",
       "      <th>think</th>\n",
       "      <th>point</th>\n",
       "      <th>new</th>\n",
       "      <th>mrs</th>\n",
       "      <th>president</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>school</th>\n",
       "      <th>have</th>\n",
       "      <th>system</th>\n",
       "      <th>like</th>\n",
       "      <th>look</th>\n",
       "      <th>come</th>\n",
       "      <th>people</th>\n",
       "      <th>2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1578</td>\n",
       "      <td>696</td>\n",
       "      <td>1926</td>\n",
       "      <td>701</td>\n",
       "      <td>536</td>\n",
       "      <td>1005</td>\n",
       "      <td>599</td>\n",
       "      <td>1457</td>\n",
       "      <td>526</td>\n",
       "      <td>437</td>\n",
       "      <td>...</td>\n",
       "      <td>769</td>\n",
       "      <td>681</td>\n",
       "      <td>5745</td>\n",
       "      <td>528</td>\n",
       "      <td>1300</td>\n",
       "      <td>958</td>\n",
       "      <td>1433</td>\n",
       "      <td>792</td>\n",
       "      <td>826</td>\n",
       "      <td>(thirty, -, three, scotty, did, not, go, back,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1578</td>\n",
       "      <td>696</td>\n",
       "      <td>1926</td>\n",
       "      <td>701</td>\n",
       "      <td>536</td>\n",
       "      <td>1005</td>\n",
       "      <td>599</td>\n",
       "      <td>1457</td>\n",
       "      <td>526</td>\n",
       "      <td>437</td>\n",
       "      <td>...</td>\n",
       "      <td>769</td>\n",
       "      <td>681</td>\n",
       "      <td>5745</td>\n",
       "      <td>528</td>\n",
       "      <td>1300</td>\n",
       "      <td>958</td>\n",
       "      <td>1433</td>\n",
       "      <td>792</td>\n",
       "      <td>826</td>\n",
       "      <td>(where, their, sharp, edges, seemed, restless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>1578</td>\n",
       "      <td>696</td>\n",
       "      <td>1926</td>\n",
       "      <td>701</td>\n",
       "      <td>536</td>\n",
       "      <td>1005</td>\n",
       "      <td>599</td>\n",
       "      <td>1457</td>\n",
       "      <td>526</td>\n",
       "      <td>437</td>\n",
       "      <td>...</td>\n",
       "      <td>769</td>\n",
       "      <td>681</td>\n",
       "      <td>5745</td>\n",
       "      <td>528</td>\n",
       "      <td>1300</td>\n",
       "      <td>958</td>\n",
       "      <td>1433</td>\n",
       "      <td>792</td>\n",
       "      <td>826</td>\n",
       "      <td>(mickie, sat, over, his, second, whisky, -, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1578</td>\n",
       "      <td>696</td>\n",
       "      <td>1926</td>\n",
       "      <td>701</td>\n",
       "      <td>536</td>\n",
       "      <td>1005</td>\n",
       "      <td>599</td>\n",
       "      <td>1457</td>\n",
       "      <td>526</td>\n",
       "      <td>437</td>\n",
       "      <td>...</td>\n",
       "      <td>769</td>\n",
       "      <td>681</td>\n",
       "      <td>5745</td>\n",
       "      <td>528</td>\n",
       "      <td>1300</td>\n",
       "      <td>958</td>\n",
       "      <td>1433</td>\n",
       "      <td>792</td>\n",
       "      <td>826</td>\n",
       "      <td>(the, bishop, looked, at, him, coldly, and, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1578</td>\n",
       "      <td>696</td>\n",
       "      <td>1926</td>\n",
       "      <td>701</td>\n",
       "      <td>536</td>\n",
       "      <td>1005</td>\n",
       "      <td>599</td>\n",
       "      <td>1457</td>\n",
       "      <td>526</td>\n",
       "      <td>437</td>\n",
       "      <td>...</td>\n",
       "      <td>769</td>\n",
       "      <td>681</td>\n",
       "      <td>5745</td>\n",
       "      <td>528</td>\n",
       "      <td>1300</td>\n",
       "      <td>958</td>\n",
       "      <td>1433</td>\n",
       "      <td>792</td>\n",
       "      <td>826</td>\n",
       "      <td>(payne, dismounted, in, madison, place, and, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year   mr   not world    1 think point   new  mrs president  \\\n",
       "374  1578  696  1926   701  536  1005   599  1457  526       437   \n",
       "375  1578  696  1926   701  536  1005   599  1457  526       437   \n",
       "376  1578  696  1926   701  536  1005   599  1457  526       437   \n",
       "377  1578  696  1926   701  536  1005   599  1457  526       437   \n",
       "378  1578  696  1926   701  536  1005   599  1457  526       437   \n",
       "\n",
       "                           ...                         place school  have  \\\n",
       "374                        ...                           769    681  5745   \n",
       "375                        ...                           769    681  5745   \n",
       "376                        ...                           769    681  5745   \n",
       "377                        ...                           769    681  5745   \n",
       "378                        ...                           769    681  5745   \n",
       "\n",
       "    system  like look  come people    2  \\\n",
       "374    528  1300  958  1433    792  826   \n",
       "375    528  1300  958  1433    792  826   \n",
       "376    528  1300  958  1433    792  826   \n",
       "377    528  1300  958  1433    792  826   \n",
       "378    528  1300  958  1433    792  826   \n",
       "\n",
       "                                                  text  \n",
       "374  (thirty, -, three, scotty, did, not, go, back,...  \n",
       "375  (where, their, sharp, edges, seemed, restless,...  \n",
       "376  (mickie, sat, over, his, second, whisky, -, on...  \n",
       "377  (the, bishop, looked, at, him, coldly, and, sa...  \n",
       "378  (payne, dismounted, in, madison, place, and, h...  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
