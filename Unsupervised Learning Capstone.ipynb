{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this capstone, we will be examining a large amount of texts with varying characteristics, and we will be using clustering and unsupervised learning techniques to classify the texts.\n",
    "\n",
    "The corpus that we chose to examine is pulled from the NLTK corpus, and it consists of texts from 500 different sources.  Each of these sources has been categorized into one of fifteen different genre.  \n",
    "\n",
    "WE want to see if the natural language processing, clustering, and unsupervised techniques we learned can be used to find patterns in the text of each genre and be able to categorize the text into each genre accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the corpus\n",
    "from nltk.corpus import brown, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the genres in the corpus\n",
    "print(len(brown.categories()))\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    ca01\n",
       "1    ca02\n",
       "2    ca03\n",
       "3    ca04\n",
       "4    ca05\n",
       "Name: ID, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Populate the DataFrame with the fileids\n",
    "df['ID'] = brown.fileids()\n",
    "print(len(df))\n",
    "df['ID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text\n",
       "0  ca01  the fulton county grand jury said friday an in...\n",
       "1  ca02  austin , texas -- committee approval of gov. p...\n",
       "2  ca03  several defendants in the summerdale police bu...\n",
       "3  ca04  oslo the most positive element to emerge from ...\n",
       "4  ca05  east providence should organize its civil defe..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to access the corpus, we need to specify that the text in each fileid be read\n",
    "\n",
    "text = [] # Create an empty list where the text can be stored\n",
    "for each in df['ID']:\n",
    "    txt = brown.words(fileids = [each]) # This returns the text based on the fileid \n",
    "    txt = [i.lower() for i in txt]\n",
    "    txt = ' '.join(txt)\n",
    "    text.append(txt) # Add the text to the list   \n",
    "\n",
    "df['text'] = text # Create a new column in the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>the fulton county grand jury said friday an in...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca02</td>\n",
       "      <td>austin , texas -- committee approval of gov. p...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca03</td>\n",
       "      <td>several defendants in the summerdale police bu...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca04</td>\n",
       "      <td>oslo the most positive element to emerge from ...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca05</td>\n",
       "      <td>east providence should organize its civil defe...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text genre\n",
       "0  ca01  the fulton county grand jury said friday an in...  news\n",
       "1  ca02  austin , texas -- committee approval of gov. p...  news\n",
       "2  ca03  several defendants in the summerdale police bu...  news\n",
       "3  ca04  oslo the most positive element to emerge from ...  news\n",
       "4  ca05  east providence should organize its civil defe...  news"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the DataFrame with the genre of the text\n",
    "categories = []\n",
    "for each in df['ID']:\n",
    "    cat = brown.categories(fileids = [each])\n",
    "    cat = ' '.join(cat)\n",
    "    categories.append(cat)\n",
    "\n",
    "df['genre'] = categories\n",
    "\n",
    "df.head() # Take a look at the DataFrame to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learned            80\n",
       "belles_lettres     75\n",
       "lore               48\n",
       "news               44\n",
       "hobbies            36\n",
       "government         30\n",
       "romance            29\n",
       "fiction            29\n",
       "adventure          29\n",
       "editorial          27\n",
       "mystery            24\n",
       "reviews            17\n",
       "religion           17\n",
       "humor               9\n",
       "science_fiction     6\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets take a look at the number of texts per genre\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not many reviews or religion texts and even fewer humor and science fiction texts.  This could make it very hard for the clustering and unsupervised techniques to accurately classifiy these texts, and it could lead to confusion in the classification of texts from the other genre as well.  We will proceed with this in mind and remove those categories of genre if necessary.\n",
    "\n",
    "Now that we have created a DataFrame that includes both the corpus and genre from each text, we can begin to examine the text and use the techniques we learned to classify each text according to genre.  We will start with the clustering technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the tfidf vectorizer from sklearn and set the parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                            max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                            min_df=2, # only use words that appear at least twice\n",
    "                            lowercase=False, # do not convert everything to lowercase\n",
    "                            use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                            norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                            smooth_idf=True, #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "labels = df.genre\n",
    "true_k = np.unique(labels).shape[0]\n",
    "X = tfidf_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use truncated SVD to perform latent semantic analysis\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd = TruncatedSVD(true_k)\n",
    "lsa = make_pipeline(svd,Normalizer(copy=False))\n",
    "\n",
    "X = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=15, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with KMeans clustering; set the parameters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  9,  9,  0,  9,  9,  0,  9,  9,  9, 11, 11, 11, 11, 11, 12, 12,\n",
       "       12,  9,  9, 12, 12, 12,  9,  9,  6,  6,  6, 12, 12,  4,  8, 12,  0,\n",
       "        5,  6,  0, 11, 11,  9,  0,  0,  6,  5,  0,  0,  0,  0,  0,  0,  0,\n",
       "        4,  9, 11,  0,  4,  3,  9,  9,  9,  9,  0,  0,  0,  0,  0,  0,  8,\n",
       "        0,  0,  0,  8,  8,  8,  8,  2,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "       13,  0,  3,  2,  4,  4,  4, 14,  4,  4,  2,  4, 14,  2,  5,  3, 14,\n",
       "        2,  4,  4,  3,  3,  0,  8, 12,  6,  7,  7, 10,  3, 13, 13, 13,  3,\n",
       "        3,  3,  3, 13,  3,  3,  3,  8,  3,  5,  3,  2,  3,  6,  5,  6,  5,\n",
       "        6,  6,  3,  3,  6,  2, 13,  2,  3, 13,  2,  2,  2, 13, 12,  3,  2,\n",
       "        6, 14, 14, 13, 13, 13, 14,  9,  3, 13,  0,  0,  5,  3,  3,  9, 12,\n",
       "        5, 12, 12,  5,  3, 13,  1,  4, 11,  2,  6, 13, 14,  8,  5, 13,  0,\n",
       "       12, 14, 14, 14,  0,  1, 13,  8, 14, 14,  2, 14,  2,  2,  2,  1,  2,\n",
       "        2, 14,  8,  2,  2, 14, 14,  2,  0,  2,  2, 13, 14, 14,  2, 10, 12,\n",
       "        2,  8,  0,  9, 13, 14,  8,  9, 12,  2,  2,  2,  9, 14, 13, 13,  8,\n",
       "       13, 13,  9,  4, 10,  4,  2,  5, 13, 13, 10, 14,  0,  2,  9, 14, 13,\n",
       "       12,  4,  2,  2,  2,  0,  8,  2, 13,  6,  6,  0,  6,  6,  6,  6,  9,\n",
       "        6,  6,  7,  6,  0,  6,  3,  6,  9,  0,  0,  6,  6,  6,  5,  6, 14,\n",
       "        3,  6,  5,  6,  5,  3,  7,  7,  7,  3,  7,  7,  3,  7,  3,  3,  3,\n",
       "        3,  3,  3,  7,  2,  7,  7,  7,  7,  0, 14,  2,  5,  5,  5,  2,  5,\n",
       "        2,  2,  7,  2,  2,  7,  0,  0,  5,  2,  6,  6, 14,  9,  6,  6,  6,\n",
       "        5,  5,  5,  6,  2,  2,  2,  2,  1,  9, 14,  9,  3,  6,  3,  2,  2,\n",
       "        8,  8,  8,  2,  2,  6,  3,  3,  7,  7,  3,  7,  3,  3,  7,  7,  7,\n",
       "       10,  1, 10,  4, 10,  4, 10,  8,  1,  4,  1, 10, 10,  4, 10, 13,  1,\n",
       "       10, 10, 10,  1, 12,  1, 10,  1, 10, 10, 10, 10, 10,  1,  1,  1,  1,\n",
       "        1, 10, 10, 10, 10, 10, 10, 10, 10, 12,  1,  1, 10,  1, 10,  1, 10,\n",
       "        1, 10, 10, 13, 10,  1,  2, 10,  1,  1,  1,  1,  1,  1,  1,  1, 10,\n",
       "        1,  1,  1,  1,  1,  1,  1, 10, 10, 10,  1,  1,  1,  1, 10,  1,  1,\n",
       "       10, 10,  1,  1, 10, 10, 10, 10, 10,  1, 10, 10, 10, 12, 10,  1, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10,  1, 10, 10, 10,  1, 10,\n",
       "       10, 10, 10,  2, 10,  8, 10], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the group labels assigned in clustering\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 89.,  53.,  61.,  22.,  38.,  51.,  30.,  81.,  21.,  54.]),\n",
       " array([  0. ,   1.4,   2.8,   4.2,   5.6,   7. ,   8.4,   9.8,  11.2,\n",
       "         12.6,  14. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFJCAYAAADaPycGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJr4AkEx8ASCZ+AJAsv8DbkMW461/eBcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e518d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets look at the distribution of the labels\n",
    "plt.hist(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40538966494640749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at some different metrics to measure the performance of KMeans clustering\n",
    "from sklearn import metrics\n",
    "\n",
    "# metric of label giving ground truth\n",
    "metrics.homogeneity_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39306231713457851"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.completeness_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39913082971114305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.v_measure_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16730688954317716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rand index adjusted for change\n",
    "metrics.adjusted_rand_score(labels, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genre</th>\n",
       "      <th>adventure</th>\n",
       "      <th>belles_lettres</th>\n",
       "      <th>editorial</th>\n",
       "      <th>fiction</th>\n",
       "      <th>government</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>humor</th>\n",
       "      <th>learned</th>\n",
       "      <th>lore</th>\n",
       "      <th>mystery</th>\n",
       "      <th>news</th>\n",
       "      <th>religion</th>\n",
       "      <th>reviews</th>\n",
       "      <th>romance</th>\n",
       "      <th>science_fiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genre  adventure  belles_lettres  editorial  fiction  government  hobbies  \\\n",
       "k                                                                           \n",
       "0              0               5         17        0           4        1   \n",
       "1             22               2          0        7           0        0   \n",
       "2              0              22          0        0           0        1   \n",
       "3              0               0          1        0           2       15   \n",
       "4              0               3          2        4           0        0   \n",
       "5              0               1          0        0           3        3   \n",
       "6              0               0          0        0          17        6   \n",
       "7              0               0          0        0           1        2   \n",
       "8              0               6          1        1           0        2   \n",
       "9              0               5          5        0           2        0   \n",
       "10             7               3          0       15           0        1   \n",
       "11             0               0          1        0           0        0   \n",
       "12             0               3          0        1           0        1   \n",
       "13             0              11          0        1           0        4   \n",
       "14             0              14          0        0           1        0   \n",
       "\n",
       "genre  humor  learned  lore  mystery  news  religion  reviews  romance  \\\n",
       "k                                                                        \n",
       "0          0        3     3        0     6         0        1        0   \n",
       "1          1        1     1       10     0         0        0        4   \n",
       "2          1       16     7        0     0         4        1        0   \n",
       "3          0       16     6        0     0         1        1        0   \n",
       "4          0        0     1        0     1         8        0        0   \n",
       "5          0        8     4        0     2         1        0        0   \n",
       "6          0        8     2        0     5         0        0        0   \n",
       "7          0       19     0        0     0         0        0        0   \n",
       "8          1        3     1        0     1         0       13        0   \n",
       "9          0        3     2        0    13         0        0        0   \n",
       "10         6        0     0       13     0         0        0       23   \n",
       "11         0        0     1        0     7         0        0        1   \n",
       "12         0        0     5        1     9         0        0        1   \n",
       "13         0        0    10        0     0         0        1        0   \n",
       "14         0        3     5        0     0         3        0        0   \n",
       "\n",
       "genre  science_fiction  \n",
       "k                       \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   3  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   1  \n",
       "14                   0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make a crosstab that will help us analyze the performance of the clustering\n",
    "\n",
    "# create a column of the group labels assigned in clustering\n",
    "df['k'] = km.labels_ \n",
    "\n",
    "pd.crosstab(df['k'], df['genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent that KMeans clustering is having a difficult time clustering the texts based on genre.  It is having a particularly difficult time clustering belles lettres, hobbies, learned, and lore, with texts clustered in ten or more different groups.  It appears that certain genre tend to be clustered together in larger groups, including the following:\n",
    "- belles lettres and learned (k = 2, 13)\n",
    "- adventure, fiction and mystery (k = 1, 10)\n",
    "- hobbies and learned (k = 3)\n",
    "- fiction and romance (k = 10)\n",
    "\n",
    "None of the clusters are particularly 'pure' in the sense that they contain only one genre.  Only two clusters included fewer than five genre.  The breakdown according to purity is as follows:\n",
    "- k0:  8 (number of genre in the cluster)\n",
    "- k1:  9\n",
    "- k2:  8\n",
    "- k3:  7\n",
    "- k4:  6\n",
    "- k5:  7\n",
    "- k6:  5\n",
    "- k7:  3\n",
    "- k8:  9\n",
    "- k9:  6\n",
    "- k10: 8\n",
    "- k11: 4\n",
    "- k12: 7\n",
    "- k13: 6\n",
    "- k14: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, categories_train, categories_test = train_test_split(\n",
    "    text, categories, test_size=0.25, random_state=42, stratify=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 18959\n",
      "Number of features: 18959\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn.tfidfvectorizer to vectorize the data\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf=vectorizer.fit_transform(text_train)\n",
    "print(\"Number of features: %d\" % train_tfidf.get_shape()[1])\n",
    "\n",
    "test_tfidf = vectorizer.transform(text_test)\n",
    "print(\"Number of features: %d\" % test_tfidf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.328\n"
     ]
    }
   ],
   "source": [
    "# Run supervised models on the vectorized data\n",
    "\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fit = rfc.fit(train_tfidf, categories_train)\n",
    "predict = rfc.predict(test_tfidf)\n",
    "score = rfc.score(test_tfidf, categories_test)\n",
    "\n",
    "print('Random Forest Classifier Score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.30177515  0.27218935  0.27160494]\n",
      "Accuracy: 0.28 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "vector_text = vectorizer.fit_transform(text)\n",
    "cross_val_rfc = cross_val_score(rfc, vector_text, categories)\n",
    "print('Cross Validated Scores: {}'.format(cross_val_rfc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc.mean(), cross_val_rfc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Score: 0.504\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel = 'linear')\n",
    "fit_svc = svc.fit(train_tfidf, categories_train)\n",
    "predict_svc = svc.predict(test_tfidf)\n",
    "score_svc = svc.score(test_tfidf, categories_test)\n",
    "print('SVC Score: {}'.format(score_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.42011834  0.37278107  0.36419753]\n",
      "Accuracy: 0.39 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_svc = cross_val_score(svc, vector_text, categories)\n",
    "print('Cross Validated Scores: {}'.format(cross_val_svc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_svc.mean(), cross_val_svc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.392\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "fit_lr = lr.fit(train_tfidf, categories_train)\n",
    "predict_lr = lr.predict(test_tfidf)\n",
    "score_lr = lr.score(test_tfidf, categories_test)\n",
    "print('Logistic Regression Score: {}'.format(score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.30769231  0.30177515  0.29012346]\n",
      "Accuracy: 0.30 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_lr = cross_val_score(lr, vector_text, categories)\n",
    "print('Cross Validated Scores: {}'.format(cross_val_lr))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_lr.mean(), cross_val_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.504\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "fit_knn = knn.fit(train_tfidf, categories_train)\n",
    "predict_knn = knn.predict(test_tfidf)\n",
    "score_knn = knn.score(test_tfidf, categories_test)\n",
    "print('KNN Classifier Score: {}'.format(score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.52662722  0.37869822  0.31481481]\n",
      "Accuracy: 0.41 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_knn = cross_val_score(knn, vector_text, categories)\n",
    "print('Cross Validated Scores: {}'.format(cross_val_knn))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_knn.mean(), cross_val_knn.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score: 0.312\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "fit_gbc = gbc.fit(train_tfidf.toarray(), categories_train)\n",
    "predict_gbc = gbc.predict(test_tfidf.toarray())\n",
    "score_gbc = gbc.score(test_tfidf.toarray(), categories_test)\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.33727811  0.36094675  0.24074074]\n",
      "Accuracy: 0.31 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_gbc = cross_val_score(gbc, vector_text.toarray(), categories)\n",
    "print('Cross Validated Scores: {}'.format(cross_val_gbc))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_gbc.mean(), cross_val_gbc.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the unsupervised models on the texts we get pretty terrible results.  The best results come from the SVC and KNN models, but even their scores were barely above 0.500.  There just does not seem to be enough variation in the texts for the models to differentiate them based on genre.  Perhaps, as the clusters above suggest, the models are getting certain similar genres mixed up.  Furthermore, the fact that there are so few science fiction, humor, reviews, and religion texts that the models cannot be adequately trained to clasify them, and therefore the whole model is suffering.  We will test this by dropping all the science fiction, humor, reviews, and religion texts, and we will combine adventure, fiction, mystery, and romance under the title fiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction           111\n",
      "learned            80\n",
      "belles_lettres     75\n",
      "lore               48\n",
      "news               44\n",
      "hobbies            36\n",
      "government         30\n",
      "editorial          27\n",
      "Name: genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame\n",
    "df1 = df\n",
    "\n",
    "# Drop all rows that contain a science fiction, humor, reviews, or religion text\n",
    "drop_list = ['science_fiction', 'humor', 'reviews', 'religion']\n",
    "for each in drop_list:\n",
    "    df1 = df1[df1.genre != each]\n",
    "\n",
    "# Rename all adventure, mystery, and romance titles\n",
    "replace_list = ['adventure', 'mystery', 'romance']\n",
    "for each in replace_list:\n",
    "    df1 = df1.replace(each, 'fiction')\n",
    "\n",
    "# Count the number of texts from each genre\n",
    "print(df1['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17461\n",
      "Number of features: 17461\n"
     ]
    }
   ],
   "source": [
    "# Create variables for the text and genre in the new DataFrame\n",
    "text1 = df1['text']\n",
    "categories1 = df1['genre']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "text_train1, text_test1, categories_train1, categories_test1 = train_test_split(\n",
    "    text1, categories1, test_size=0.25, random_state=42, stratify=categories1)\n",
    "\n",
    "#Applying the vectorizer\n",
    "train_tfidf1 = vectorizer.fit_transform(text_train1)\n",
    "print(\"Number of features: %d\" % train_tfidf1.get_shape()[1])\n",
    "\n",
    "test_tfidf1 = vectorizer.transform(text_test1)\n",
    "print(\"Number of features: %d\" % test_tfidf1.get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.5132743362831859\n"
     ]
    }
   ],
   "source": [
    "# Run the supervised model on the vectorized data in the new DataFrame\n",
    "\n",
    "# Random forest classifier\n",
    "fit_rfc1 = rfc.fit(train_tfidf1, categories_train1)\n",
    "predict_rfc1 = rfc.predict(test_tfidf1)\n",
    "score_rfc1 = rfc.score(test_tfidf1, categories_test1)\n",
    "\n",
    "print('Random Forest Classifier Score: {}'.format(score_rfc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Scores: [ 0.52317881  0.41059603  0.4966443 ]\n",
      "Accuracy: 0.48 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "vector_text1 = vectorizer.fit_transform(text1)\n",
    "cross_val_rfc1 = cross_val_score(rfc, vector_text1, categories1)\n",
    "print('Cross Validated RFC Scores: {}'.format(cross_val_rfc1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_rfc1.mean(), cross_val_rfc1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Score: 0.6371681415929203\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "fit_svc1 = svc.fit(train_tfidf1, categories_train1)\n",
    "predict_svc1 = svc.predict(test_tfidf1)\n",
    "score_svc1 = svc.score(test_tfidf1, categories_test1)\n",
    "print('SVC Score: {}'.format(score_svc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated SVC Scores: [ 0.62913907  0.53642384  0.55704698]\n",
      "Accuracy: 0.57 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_svc1 = cross_val_score(svc, vector_text1, categories1)\n",
    "print('Cross Validated SVC Scores: {}'.format(cross_val_svc1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_svc1.mean(), cross_val_svc1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.4778761061946903\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "fit_lr1 = lr.fit(train_tfidf1, categories_train1)\n",
    "predict_lr1 = lr.predict(test_tfidf1)\n",
    "score_lr1 = lr.score(test_tfidf1, categories_test1)\n",
    "print('Logistic Regression Score: {}'.format(score_lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated LR Scores: [ 0.52980132  0.42384106  0.46308725]\n",
      "Accuracy: 0.47 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_lr1 = cross_val_score(lr, vector_text1, categories1)\n",
    "print('Cross Validated LR Scores: {}'.format(cross_val_lr1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_lr1.mean(), cross_val_lr1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.6460176991150443\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "fit_knn1 = knn.fit(train_tfidf1, categories_train1)\n",
    "predict_knn1 = knn.predict(test_tfidf1)\n",
    "score_knn1 = knn.score(test_tfidf1, categories_test1)\n",
    "print('KNN Classifier Score: {}'.format(score_knn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated KNN Classifier Scores: [ 0.60927152  0.52980132  0.52348993]\n",
      "Accuracy: 0.55 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_knn1 = cross_val_score(knn, vector_text1, categories1)\n",
    "print('Cross Validated KNN Classifier Scores: {}'.format(cross_val_knn1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_knn1.mean(), cross_val_knn1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score: 0.5486725663716814\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting classifier\n",
    "fit_gbc1 = gbc.fit(train_tfidf1.toarray(), categories_train1)\n",
    "predict_gbc1 = gbc.predict(test_tfidf1.toarray())\n",
    "score_gbc1 = gbc.score(test_tfidf1.toarray(), categories_test1)\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score_gbc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated GBC Scores: [ 0.54966887  0.52980132  0.45637584]\n",
      "Accuracy: 0.51 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cross_val_gbc1 = cross_val_score(gbc, vector_text1.toarray(), categories1)\n",
    "print('Cross Validated GBC Scores: {}'.format(cross_val_gbc1))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cross_val_gbc1.mean(), cross_val_gbc1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping science fiction, humor, reviews, and religion, as well as combining adventure, fiction, mystery, and romance, increased the accuracy of the unsupervised models.  That being said, the models are still performing very poorly.  The SVC and KNN models were still the best performing models with a scores of only 0.637 and 0.646, respectively.  However, the increased performance of each of the models suggests that dropping genres with few texts and combining similar genres together was, in fact, effective in improving the performance of the models.\n",
    "\n",
    "In order to try to continue to improve the performance of the models, we will add more features using the bag-of-words method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 10 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(11)]\n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df_bow = pd.DataFrame(columns=common_words)\n",
    "    df_bow['text'] = df_new['text']\n",
    "    df_bow.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, corp in enumerate(df_bow['text']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in corp\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df_bow.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames that isolate texts be genre\n",
    "\n",
    "# fiction\n",
    "df_fic = df1\n",
    "df_fic = df_fic[df_fic.genre == 'fiction' ]\n",
    "\n",
    "# learned\n",
    "df_learn = df1\n",
    "df_learn = df_learn[df_learn.genre == 'learned']\n",
    "\n",
    "# belles_lettres\n",
    "df_bell = df1\n",
    "df_bell = df_bell[df_bell.genre == 'belles_lettres']\n",
    "\n",
    "# lore\n",
    "df_lore = df1\n",
    "df_lore = df_lore[df_lore.genre == 'lore']\n",
    "\n",
    "# news\n",
    "df_news = df1\n",
    "df_news = df_news[df_news.genre == 'news']\n",
    "\n",
    "# hobbies\n",
    "df_hob = df1\n",
    "df_hob = df_hob[df_hob.genre == 'hobbies']\n",
    "\n",
    "# government\n",
    "df_gov = df1\n",
    "df_gov = df_gov[df_gov.genre == 'government']\n",
    "\n",
    "# editorial\n",
    "df_ed = df1\n",
    "df_ed = df_ed[df_ed.genre == 'editorial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Combine all the texts from each genre. Parse each newly created text.\n",
    "# Remove the `` from the text because it pops up as one of the most common words for each\n",
    "# genre.\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "df_fic['text'] = df_fic['text'].str.replace('``', '')\n",
    "fiction = ''.join(df_fic['text'].tolist())\n",
    "fiction = nlp(fiction)\n",
    "\n",
    "df_learn['text'] = df_learn['text'].str.replace('``', '')\n",
    "learned = ''.join(df_learn['text'].tolist())\n",
    "learned = nlp(learned)\n",
    "\n",
    "df_bell['text'] = df_bell['text'].str.replace('``', '')\n",
    "belles = ''.join(df_bell['text'].tolist())\n",
    "belles = nlp(belles)\n",
    "\n",
    "#lore\n",
    "df_lore['text'] = df_lore['text'].str.replace('``', '')\n",
    "lore = ''.join(df_lore['text'].tolist())\n",
    "lore = nlp(lore)\n",
    "\n",
    "# news\n",
    "df_news['text'] = df_news['text'].str.replace('``', '')\n",
    "news = ''.join(df_news['text'].tolist())\n",
    "news = nlp(news)\n",
    "\n",
    "#hob\n",
    "df_hob['text'] = df_hob['text'].str.replace('``', '')\n",
    "hobbies = ''.join(df_hob['text'].tolist())\n",
    "hobbies = nlp(hobbies)\n",
    "\n",
    "df_gov['text'] = df_gov['text'].str.replace('``', '')\n",
    "government= ''.join(df_gov['text'].tolist())\n",
    "government = nlp(government)\n",
    "\n",
    "df_ed['text'] = df_ed['text'].str.replace('``', '')\n",
    "editorial = ''.join(df_ed['text'].tolist())\n",
    "editorial = nlp(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the parsed texts through the bag-of-words function to find the most common words\n",
    "# for each genre.\n",
    "fiction_bow = bag_of_words(fiction)\n",
    "learned_bow = bag_of_words(learned)\n",
    "belles_bow = bag_of_words(belles)\n",
    "lore_bow = bag_of_words(lore)\n",
    "news_bow = bag_of_words(news)\n",
    "hobbies_bow = bag_of_words(hobbies)\n",
    "government_bow = bag_of_words(government)\n",
    "editorial_bow = bag_of_words(editorial)\n",
    "\n",
    "# Combine the bags to create a set of unique words\n",
    "common_words = set(fiction_bow + learned_bow + belles_bow + lore_bow + news_bow + hobbies_bow + government_bow + editorial_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Parse each of the texts individually\n",
    "\n",
    "# Fiction\n",
    "rar_list = []\n",
    "for each in df_fic['text']:\n",
    "    rar_list.append(each)\n",
    "rar_list1 = []\n",
    "for each in rar_list:\n",
    "    t = nlp(each)\n",
    "    rar_list1.append(t)\n",
    "df_fic['text'] = rar_list1\n",
    "\n",
    "# Learned\n",
    "star_list = []\n",
    "for each in df_learn['text']:\n",
    "    star_list.append(each)\n",
    "sun_list = []\n",
    "for each in star_list:\n",
    "    t = nlp(each)\n",
    "    sun_list.append(t)\n",
    "df_learn['text'] = sun_list\n",
    "\n",
    "# Belles Lettres\n",
    "star_list1 = []\n",
    "for each in df_bell['text']:\n",
    "    star_list1.append(each)\n",
    "sun_list1 = []\n",
    "for each in star_list1:\n",
    "    t = nlp(each)\n",
    "    sun_list1.append(t)\n",
    "df_bell['text'] = sun_list1\n",
    "\n",
    "# Lore\n",
    "star_list2 = []\n",
    "for each in df_lore['text']:\n",
    "    star_list2.append(each)\n",
    "sun_list2 = []\n",
    "for each in star_list2:\n",
    "    t = nlp(each)\n",
    "    sun_list2.append(t)\n",
    "df_lore['text'] = sun_list2\n",
    "\n",
    "# News\n",
    "star_list3 = []\n",
    "for each in df_news['text']:\n",
    "    star_list3.append(each)\n",
    "sun_list3 = []\n",
    "for each in star_list3:\n",
    "    t = nlp(each)\n",
    "    sun_list3.append(t)\n",
    "df_news['text'] = sun_list3\n",
    "\n",
    "# Hobbies\n",
    "star_list4 = []\n",
    "for each in df_hob['text']:\n",
    "    star_list4.append(each)\n",
    "sun_list4 = []\n",
    "for each in star_list4:\n",
    "    t = nlp(each)\n",
    "    sun_list4.append(t)\n",
    "df_hob['text'] = sun_list4\n",
    "\n",
    "# Government\n",
    "star_list5 = []\n",
    "for each in df_gov['text']:\n",
    "    star_list5.append(each)\n",
    "sun_list5 = []\n",
    "for each in star_list5:\n",
    "    t = nlp(each)\n",
    "    sun_list5.append(t)\n",
    "df_gov['text'] = sun_list5\n",
    "\n",
    "# Editorials\n",
    "star_list6 = []\n",
    "for each in df_ed['text']:\n",
    "    star_list6.append(each)\n",
    "sun_list6 = []\n",
    "for each in star_list6:\n",
    "    t = nlp(each)\n",
    "    sun_list6.append(t)\n",
    "df_ed['text'] = sun_list6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "      <th>k</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ck01</td>\n",
       "      <td>(thirty, -, three, scotty, did, not, go, back,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>10</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ck02</td>\n",
       "      <td>(where, their, sharp, edges, seemed, restless,...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ck03</td>\n",
       "      <td>(mickie, sat, over, his, second, whisky, -, on...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>10</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ck04</td>\n",
       "      <td>(the, bishop, looked, at, him, coldly, and, sa...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>4</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ck05</td>\n",
       "      <td>(payne, dismounted, in, madison, place, and, h...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>10</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               text    genre   k  index\n",
       "0  ck01  (thirty, -, three, scotty, did, not, go, back,...  fiction  10    374\n",
       "1  ck02  (where, their, sharp, edges, seemed, restless,...  fiction   1    375\n",
       "2  ck03  (mickie, sat, over, his, second, whisky, -, on...  fiction  10    376\n",
       "3  ck04  (the, bishop, looked, at, him, coldly, and, sa...  fiction   4    377\n",
       "4  ck05  (payne, dismounted, in, madison, place, and, h...  fiction  10    378"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another new DataFrame containing all the individually parsed texts\n",
    "df_new = pd.concat([df_fic, df_learn, df_bell, df_lore, df_news, df_hob, df_gov, df_ed])\n",
    "\n",
    "# Add a column that contains the index numbers \n",
    "df_new['index'] = df_new.index\n",
    "\n",
    "# Reset the index\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n"
     ]
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<451x20647 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 240774 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column using df_new.index and df_new.genre\n",
    "word_counts['index'] = df_new['index']\n",
    "word_counts['genre'] = df_new['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>...</th>\n",
       "      <th>a20637</th>\n",
       "      <th>a20638</th>\n",
       "      <th>a20639</th>\n",
       "      <th>a20640</th>\n",
       "      <th>a20641</th>\n",
       "      <th>a20642</th>\n",
       "      <th>a20643</th>\n",
       "      <th>a20644</th>\n",
       "      <th>a20645</th>\n",
       "      <th>a20646</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a0        a1   a2   a3   a4   a5   a6   a7   a8        a9   ...    a20637  \\\n",
       "0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.010579   ...       0.0   \n",
       "1  0.0  0.104096  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.011233   ...       0.0   \n",
       "2  0.0  0.033864  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.076740   ...       0.0   \n",
       "3  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000   ...       0.0   \n",
       "4  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.025149   ...       0.0   \n",
       "\n",
       "   a20638  a20639  a20640  a20641  a20642  a20643  a20644  a20645  a20646  \n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 20647 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame that will include the vectorized text\n",
    "\n",
    "# Create a list of a + number that we will use for our vectorized text column names\n",
    "list_ = ['a'+str(i) for i in range(20647)]\n",
    "df_last = pd.DataFrame(vector_text1.toarray(), columns = list_)\n",
    "df_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a column for df_last that contains the index numbers\n",
    "df_last['index'] = df_last.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge DataFrames word_counts and df_last on the index so that the vectorized text features \n",
    "# and the bag-of-word features are included in the same DataFrame\n",
    "df_last = pd.merge(df_last, word_counts, how='inner', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create target and predictor variables; normalize the predictor variables\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "features = df_last.drop(['text', 'genre', 'index'], axis=1)\n",
    "features = normalize(features)\n",
    "target_var = df_last['genre']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "feat_train, feat_test, genre_train, genre_test = train_test_split(\n",
    "    features, target_var, test_size=0.25, random_state=0, stratify=target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score: 0.3592233009708738\n",
      "Cross Validated Scores: [ 0.4057971   0.39855072  0.31111111]\n",
      "Accuracy: 0.37 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "# Run the supervised models on the DataFrame---\n",
    "# Random Forest, Support Vector Machine, Logistic Regression, KNN, Gradient Boosting\n",
    "\n",
    "# Random Forest\n",
    "fit_rfc2 = rfc.fit(feat_train, genre_train)\n",
    "predict_rfc2 = rfc.predict(feat_test)\n",
    "score_rfc2 = rfc.score(feat_test, genre_test)\n",
    "print('Random Forest Classifier Score: {}'.format(score_rfc2))\n",
    "\n",
    "# Cross-validate\n",
    "cvs_rfc2 = cross_val_score(rfc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_rfc2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_rfc2.mean(), cvs_rfc2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Score: 0.5922330097087378\n",
      "Cross Validated Scores: [ 0.5942029   0.46376812  0.47407407]\n",
      "Accuracy: 0.51 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "fit_svc2 = svc.fit(feat_train, genre_train)\n",
    "predict_svc2 = svc.predict(feat_test)\n",
    "score_svc2 = svc.score(feat_test, genre_test)\n",
    "print('Support Vector Classifier Score: {}'.format(score_svc2))\n",
    "\n",
    "# Cross-validate\n",
    "cvs_svc2 = cross_val_score(svc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_svc2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_svc2.mean(), cvs_svc2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.6116504854368932\n",
      "Cross Validated Scores: [ 0.56521739  0.42753623  0.47407407]\n",
      "Accuracy: 0.49 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "fit_lr2 = lr.fit(feat_train, genre_train)\n",
    "predict_lr2 = lr.predict(feat_test)\n",
    "score_lr2 = lr.score(feat_test, genre_test)\n",
    "print('Logistic Regression Score: {}'.format(score_lr2))\n",
    "\n",
    "# Cross-validate\n",
    "cvs_lr2 = cross_val_score(lr, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_lr2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_lr2.mean(), cvs_lr2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Score: 0.5145631067961165\n",
      "Cross Validated Scores: [ 0.54347826  0.39855072  0.42222222]\n",
      "Accuracy: 0.45 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "fit_knn2 = knn.fit(feat_train, genre_train)\n",
    "predict_knn2 = knn.predict(feat_test)\n",
    "score_knn2 = knn.score(feat_test, genre_test)\n",
    "print('KNN Classifier Score: {}'.format(score_knn2))\n",
    "\n",
    "# Cross-validate\n",
    "cvs_knn2 = cross_val_score(knn, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_knn2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_knn2.mean(), cvs_knn2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score: 0.5825242718446602\n",
      "Cross Validated Scores: [ 0.36956522  0.44202899  0.41481481]\n",
      "Accuracy: 0.41 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "fit_gbc2 = gbc.fit(feat_train, genre_train)\n",
    "predict_gbc2 = gbc.predict(feat_test)\n",
    "score_gbc2 = gbc.score(feat_test, genre_test)\n",
    "print('Gradient Boosting Classifier Score: {}'.format(score_gbc2))\n",
    "\n",
    "# Cross-validate\n",
    "cvs_gbc2 = cross_val_score(gbc, features, target_var)\n",
    "print('Cross Validated Scores: {}'.format(cvs_gbc2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvs_gbc2.mean(), cvs_gbc2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unsupervised learning models did not improve when adding bag-of-word features to the models.  The best model before cross-validation is the logistic regression with a score or 0.611, but after cross-validation the best model is the SVC, with accuracy or 0.51 (+/- 0.12). \n",
    "\n",
    "The results of the unsupervised models and the clustering are disappointing.  The texts of each genre do not appear to be sufficiently distinct for the models to accurately categorize them.  I thought that the belles lettres may have been the cause of the confusion because belles lettres is considered more of a style of writing than a genre, and the subject of belles lettres can be many things, including many of the genres into which we are trying to classify the texts.  However, the performance of the models did not improve after dropping belles lettres from the DataFrame and retrying the clustering and unsupervised techniques. \n",
    "\n",
    "Another possible cause for the poor performance of the clustering and unsupervised models may be that the texts are written by a variety of different authors, each with their own distinct style, which would make it more difficult for the models to categorize based on genre. Unfortunately this particulary body of texts does not have the authors included with the text and genre.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
